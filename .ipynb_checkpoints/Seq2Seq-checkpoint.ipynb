{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv, re, copy\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import *\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from nltk.tree import Tree\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentences(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    sentences = [row for row in reader]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAllTextSentences():\n",
    "    sentences = loadSentences('dataset/Training.sentence')\n",
    "    sentences.extend(loadSentences('dataset/SampleSet.sentence'))\n",
    "    sentences.extend(loadSentences('dataset/Task1NeuV3_corrected.sentence'))\n",
    "    # print(len(sentences))\n",
    "    TextSentenceID = dict()\n",
    "    vocabulary = set()\n",
    "    for line in sentences:\n",
    "        id = line['Sentence-ID'][4:]\n",
    "        text = line['Sentence']\n",
    "        output = nlp.annotate(text, properties={'annotators': 'tokenize', 'outputFormat': 'json'})\n",
    "#         print('---------------------------------------------')\n",
    "        if id not in TextSentenceID:\n",
    "            TextSentenceID[id] = {'id': id,\n",
    "                                  'text': text,\n",
    "                                  'pmid': line['PMID'],\n",
    "                                  'tokens': [i['word'] for i in output['tokens']]}\n",
    "            vocabulary = vocabulary.union(set(TextSentenceID[id]['tokens']))\n",
    "    #     else:\n",
    "    #         assert (TextSentenceID[id]['text'] == line['Sentence']), 'ID: %s \\n Text1: %s \\n Text2: %s'%(id, TextSentenceID[id]['text'], line['Sentence']) \n",
    "    #         assert (TextSentenceID[id]['pmid'] == line['PMID']), 'ID: %s \\n PMID1: %s \\n PMID2: %s'%(id, TextSentenceID[id]['pmid'], line['PMID'])\n",
    "    print('Download text sentences:', len(TextSentenceID), 'sentences')\n",
    "    # print(TextSentenceID['10000072']) \n",
    "    # {'id': '10000072', 'text': 'it was found that a 6-fold increase in Fdft1 activity compared with that of the wild-type did not cause significant changes in HmgCoA reductase activity, while the amounts of synthesized dolichols and ergosterols increased by 80 and 32 percent respectively.', 'pmid': '10623644'}\n",
    "    return TextSentenceID, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download text sentences: 6536 sentences\n",
      "{'id': '10000072', 'text': 'it was found that a 6-fold increase in Fdft1 activity compared with that of the wild-type did not cause significant changes in HmgCoA reductase activity, while the amounts of synthesized dolichols and ergosterols increased by 80 and 32 percent respectively.', 'pmid': '10623644', 'tokens': ['it', 'was', 'found', 'that', 'a', '6-fold', 'increase', 'in', 'Fdft1', 'activity', 'compared', 'with', 'that', 'of', 'the', 'wild-type', 'did', 'not', 'cause', 'significant', 'changes', 'in', 'HmgCoA', 'reductase', 'activity', ',', 'while', 'the', 'amounts', 'of', 'synthesized', 'dolichols', 'and', 'ergosterols', 'increased', 'by', '80', 'and', '32', 'percent', 'respectively', '.']}\n",
      "19036\n"
     ]
    }
   ],
   "source": [
    "TextSentenceID, vocabulary = loadAllTextSentences()\n",
    "print(TextSentenceID['10000072'])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.25327557e-01 -2.05734119e-01  2.20678654e-02  1.27095148e-01\n",
      "  4.70568202e-02  3.66582334e-01  1.80289820e-01 -6.96827620e-02\n",
      "  5.25160849e-01  2.50934307e-02  1.86377347e-01 -1.57668844e-01\n",
      "  5.11006951e-01  2.82196283e-01 -1.45905316e-01 -1.02183104e-01\n",
      " -1.58878171e-03 -2.69769728e-01  4.36125807e-02 -3.74512225e-02\n",
      "  1.44765481e-01 -1.72953263e-01  5.64784929e-02  2.03118950e-01\n",
      " -2.29118302e-01 -3.89206707e-01  1.89598396e-01  8.48720893e-02\n",
      " -2.92850465e-01 -1.89046666e-01  3.03188503e-01 -4.85944226e-02\n",
      "  2.32507274e-01  1.78006619e-01  9.79960859e-02  6.02323450e-02\n",
      "  1.65033221e-01 -3.79372507e-01  1.18517898e-01 -1.47823170e-01\n",
      "  1.21478774e-01 -2.50081658e-01  2.41490863e-02  1.28086820e-01\n",
      "  3.87153685e-01 -1.73163749e-02 -1.84716210e-01 -2.07878187e-01\n",
      "  9.35073644e-02  3.20446283e-01  6.42037690e-02 -4.05614406e-01\n",
      "  7.49878660e-02 -1.26757715e-02  1.44438535e-01 -3.08646530e-01\n",
      "  1.06738694e-02  2.82481462e-01 -2.62360632e-01 -2.80956089e-01\n",
      " -1.86210290e-01 -1.15877595e-02 -1.58727970e-02 -1.02932915e-01\n",
      "  3.61133039e-01 -8.23537931e-02 -2.83741858e-03  5.16191423e-02\n",
      " -4.18368340e-01 -1.50543869e-01  2.32713625e-01  1.58457551e-02\n",
      "  7.49532357e-02 -2.56549895e-01  3.43764037e-01  2.38093615e-01\n",
      " -4.25283492e-01 -1.25486001e-01  1.66954264e-01  4.11511660e-02\n",
      " -1.69186573e-02 -1.92248717e-01  3.99735570e-01 -1.94719046e-01\n",
      " -2.46572997e-02  1.49890766e-01  4.76957671e-02  3.81951362e-01\n",
      "  1.08876072e-01  2.77450144e-01 -2.29126096e-01  2.58556068e-01\n",
      " -4.57857177e-02  5.42829782e-02 -1.10890254e-01 -2.01238692e-01\n",
      "  1.17767565e-01 -3.11075300e-01 -2.99588665e-02 -1.47615382e-02\n",
      "  4.28586006e-01  4.25316632e-01  1.92770615e-01 -5.87228499e-03\n",
      "  8.98397528e-03 -1.76456189e-04 -1.32660881e-01 -2.93322261e-02\n",
      " -1.97634950e-01  1.88606381e-01  7.76417330e-02 -1.28206015e-01\n",
      "  5.40913865e-02 -3.86624575e-01  4.84502800e-02 -5.41283712e-02\n",
      " -2.43484527e-01  4.76339050e-02  3.32977958e-02 -1.33472949e-01\n",
      "  5.08810759e-01 -2.07310498e-01 -2.18785211e-01 -2.15726122e-01\n",
      " -2.37135991e-01 -1.21456228e-01 -9.52737182e-02 -2.20923349e-01\n",
      "  1.73350364e-01  1.73229873e-01 -1.97473794e-01  1.51687950e-01\n",
      " -2.95273393e-01  1.54850528e-01 -5.90961659e-03 -1.79703921e-01\n",
      " -5.72281480e-02  1.62768081e-01  1.81678291e-02 -1.77953675e-01\n",
      " -2.27385700e-01 -3.52959707e-02  1.82563767e-01 -1.61678255e-01\n",
      "  4.25200760e-02  9.31143686e-02 -3.57891917e-01 -3.55402052e-01\n",
      " -2.97917217e-01  9.88947228e-02  2.28375435e-01  5.32136083e-01\n",
      "  3.74176502e-02 -3.60787958e-01 -1.39900863e-01  1.00078294e-03\n",
      " -9.83410925e-02 -1.41357124e-01  2.20851153e-01 -1.13046043e-01\n",
      "  4.87643667e-03 -1.32825494e-01  3.95833731e-01 -1.83650386e-02\n",
      "  1.80350214e-01  2.15704367e-01  5.28760105e-02  1.05752304e-01\n",
      "  2.86088765e-01  4.28989083e-01  1.75798118e-01  1.41190872e-01\n",
      "  2.28342578e-01 -2.38321200e-01 -2.94696212e-01  7.83535987e-02\n",
      "  1.20306291e-01 -2.19977051e-01 -6.22638948e-02 -1.18336909e-01\n",
      " -3.01841293e-02 -1.91611070e-02  2.57388890e-01  3.80244777e-02\n",
      " -8.39182809e-02  2.82942861e-01  9.14376304e-02  1.25304610e-01\n",
      " -1.01024613e-01 -1.06362179e-01  8.64111558e-02  9.60571133e-03\n",
      " -1.11674331e-01  3.23287606e-01  2.64685571e-01  3.73143911e-01\n",
      "  2.59604715e-02 -5.62201403e-02  7.41463751e-02 -9.38247368e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('word_embeddings/PubMed-and-PMC-w2v.bin', binary=True)\n",
    "print(word_vectors['Increases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.77897915e-01 -6.07956201e-02  1.82623565e-01  9.40433890e-03\n",
      " -4.57968228e-02  1.06524616e-01  3.05105671e-02 -1.31171560e-02\n",
      "  2.61207402e-01 -7.96180367e-02  2.10063905e-01 -2.63688445e-01\n",
      "  3.40338528e-01  4.86342199e-02 -1.47659093e-01 -4.99520265e-02\n",
      " -6.67950213e-02 -3.32690239e-01 -5.26371263e-02  1.95578754e-01\n",
      "  3.12451199e-02 -4.54581976e-02 -1.43305317e-01  6.22850917e-02\n",
      " -1.26622334e-01 -1.32162586e-01  1.25042289e-01 -6.89747334e-02\n",
      "  6.96995528e-03 -2.80402958e-01  8.84695575e-02 -2.48210698e-01\n",
      "  4.07526689e-03 -1.68188468e-01  4.15355772e-01  8.11652094e-02\n",
      "  1.10174470e-01  5.04403608e-03  1.02366670e-03 -1.77017331e-01\n",
      "  4.66788188e-02 -1.58089146e-01  1.15800232e-01 -9.48347151e-02\n",
      "  1.79338381e-01  1.55628501e-02 -7.92423785e-02 -2.33671039e-01\n",
      "  1.54874176e-01  2.62574106e-02 -2.71606948e-02 -2.14085847e-01\n",
      " -3.42812538e-02  2.45975465e-01 -1.43955141e-01 -1.01725556e-01\n",
      " -9.12490115e-03  1.26160726e-01 -1.70875147e-01 -1.63989186e-01\n",
      " -1.38413506e-02  5.44368215e-02 -2.02857461e-02 -1.57564059e-01\n",
      "  2.19620362e-01 -2.14499049e-02 -1.24971708e-02  2.52309829e-01\n",
      " -2.94935644e-01 -1.57698005e-01  1.37900069e-01 -3.94589677e-02\n",
      " -9.63022560e-02 -2.65487395e-02 -1.63250435e-02  1.67939499e-01\n",
      "  3.58018442e-03  1.92325283e-02  1.87809914e-01 -7.93541819e-02\n",
      " -1.45845227e-02 -1.40784696e-01  9.29493308e-02  1.03057800e-02\n",
      "  6.72936253e-03  1.12243094e-01 -5.26990630e-02  1.28385812e-01\n",
      "  1.90362871e-01  7.88735002e-02 -2.75441617e-01  5.31765781e-02\n",
      "  2.50314567e-02 -9.23432261e-02  3.30367610e-02  1.78892910e-02\n",
      " -1.38366833e-01 -1.23391319e-02  2.98500538e-01 -1.84966177e-01\n",
      "  2.16321573e-01  2.91993469e-01 -7.69648999e-02 -7.19145965e-03\n",
      "  1.59557834e-01 -9.06543583e-02  1.75642388e-04  3.07149559e-01\n",
      " -8.05862844e-02  1.92143068e-01 -6.43031001e-02 -5.37504181e-02\n",
      "  8.97608250e-02 -1.34542525e-01  5.80316968e-02  8.68189242e-03\n",
      " -1.04180746e-01  6.46408275e-02 -2.87191402e-02 -1.12109110e-01\n",
      "  3.75786155e-01 -1.12525813e-01 -7.68224299e-02 -2.43063182e-01\n",
      " -8.59607533e-02 -1.73819691e-01 -1.91132784e-01 -5.37690409e-02\n",
      "  1.19617291e-01 -8.29374492e-02 -4.54027317e-02  6.08594455e-02\n",
      " -2.02379283e-02 -8.61751661e-02 -1.99317262e-02 -1.51314318e-01\n",
      " -1.57840908e-01 -1.60522491e-03 -4.25990224e-02  1.20317906e-01\n",
      " -5.66324182e-02  3.96984629e-02 -4.78619896e-02 -8.01960826e-02\n",
      " -3.54666263e-02 -7.69035444e-02 -6.42876253e-02 -3.08689654e-01\n",
      "  2.26556897e-01  4.05272283e-02  1.55991942e-01  6.20780997e-02\n",
      "  1.46457508e-01 -8.12545493e-02 -7.91816786e-02 -7.33875632e-02\n",
      "  8.18730220e-02 -7.79907927e-02  3.79798263e-01 -1.28965437e-01\n",
      "  1.94463823e-02 -7.18932524e-02  3.16320688e-01  1.83533639e-01\n",
      "  8.84350762e-03 -3.82002853e-02  1.32843405e-01  1.49493799e-01\n",
      "  2.79057422e-03  1.42002895e-01  1.38417870e-01 -1.70455799e-01\n",
      "  5.97284883e-02 -5.09720780e-02 -2.08913773e-01 -1.79159753e-02\n",
      "  2.16881052e-01 -5.87030053e-01 -3.20306532e-02 -2.41553411e-04\n",
      " -1.61274746e-01  2.31321175e-02  1.94668286e-02 -6.78434875e-03\n",
      " -8.97978619e-02  1.58379242e-01 -5.12850694e-02  8.80876929e-02\n",
      " -1.51118666e-01  5.47820777e-02 -8.73479173e-02  5.65561466e-02\n",
      " -2.25299329e-01  2.92401046e-01  7.12783076e-03  1.57949433e-01\n",
      "  1.50169969e-01 -1.73611511e-02  3.75429844e-03 -1.02139115e-01]\n",
      "1564\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 200\n",
    "T_vocab_size = 50000\n",
    "T_idx2w = ['_', 'unk'] + list(vocabulary) \n",
    "for word in word_vectors.vocab.keys():\n",
    "    if word not in T_idx2w:\n",
    "        T_idx2w.append(word)\n",
    "    if len(T_index2w) >= T_vocab_size + 2:\n",
    "        break\n",
    "T_idx2w.extend(['start_id', 'end_id'])\n",
    "T_w2idx = dict([(T_idx2w[i], i) for i in range(len(T_idx2w))])\n",
    "T_vocab_size_total = len(T_idx2w)\n",
    "word_embedding = np.random.uniform(-0.1, 0.1, (2, emb_dim))\n",
    "count = 2\n",
    "for i in range(2, T_vocab_size_total-2):\n",
    "    if T_idx2w[i] in word_vectors.vocab:\n",
    "#         print(word_embedding.shape, np.array([word_vectors[T_idx2w[i]]]).shape)\n",
    "        word_embedding = np.append(word_embedding, [word_vectors[T_idx2w[i]]], axis = 0)\n",
    "    else:\n",
    "        word_embedding = np.append(word_embedding, [np.random.uniform(-0.1, 0.1, emb_dim)], axis = 0)\n",
    "        count += 1\n",
    "word_embedding = np.append(word_embedding, [np.random.uniform(-0.1, 0.1, emb_dim)], axis = 0)\n",
    "print(word_embedding[T_w2idx['increases']])\n",
    "print(count+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.77897915e-01 -6.07956201e-02  1.82623565e-01  9.40433890e-03\n",
      " -4.57968228e-02  1.06524616e-01  3.05105671e-02 -1.31171560e-02\n",
      "  2.61207402e-01 -7.96180367e-02  2.10063905e-01 -2.63688445e-01\n",
      "  3.40338528e-01  4.86342199e-02 -1.47659093e-01 -4.99520265e-02\n",
      " -6.67950213e-02 -3.32690239e-01 -5.26371263e-02  1.95578754e-01\n",
      "  3.12451199e-02 -4.54581976e-02 -1.43305317e-01  6.22850917e-02\n",
      " -1.26622334e-01 -1.32162586e-01  1.25042289e-01 -6.89747334e-02\n",
      "  6.96995528e-03 -2.80402958e-01  8.84695575e-02 -2.48210698e-01\n",
      "  4.07526689e-03 -1.68188468e-01  4.15355772e-01  8.11652094e-02\n",
      "  1.10174470e-01  5.04403608e-03  1.02366670e-03 -1.77017331e-01\n",
      "  4.66788188e-02 -1.58089146e-01  1.15800232e-01 -9.48347151e-02\n",
      "  1.79338381e-01  1.55628501e-02 -7.92423785e-02 -2.33671039e-01\n",
      "  1.54874176e-01  2.62574106e-02 -2.71606948e-02 -2.14085847e-01\n",
      " -3.42812538e-02  2.45975465e-01 -1.43955141e-01 -1.01725556e-01\n",
      " -9.12490115e-03  1.26160726e-01 -1.70875147e-01 -1.63989186e-01\n",
      " -1.38413506e-02  5.44368215e-02 -2.02857461e-02 -1.57564059e-01\n",
      "  2.19620362e-01 -2.14499049e-02 -1.24971708e-02  2.52309829e-01\n",
      " -2.94935644e-01 -1.57698005e-01  1.37900069e-01 -3.94589677e-02\n",
      " -9.63022560e-02 -2.65487395e-02 -1.63250435e-02  1.67939499e-01\n",
      "  3.58018442e-03  1.92325283e-02  1.87809914e-01 -7.93541819e-02\n",
      " -1.45845227e-02 -1.40784696e-01  9.29493308e-02  1.03057800e-02\n",
      "  6.72936253e-03  1.12243094e-01 -5.26990630e-02  1.28385812e-01\n",
      "  1.90362871e-01  7.88735002e-02 -2.75441617e-01  5.31765781e-02\n",
      "  2.50314567e-02 -9.23432261e-02  3.30367610e-02  1.78892910e-02\n",
      " -1.38366833e-01 -1.23391319e-02  2.98500538e-01 -1.84966177e-01\n",
      "  2.16321573e-01  2.91993469e-01 -7.69648999e-02 -7.19145965e-03\n",
      "  1.59557834e-01 -9.06543583e-02  1.75642388e-04  3.07149559e-01\n",
      " -8.05862844e-02  1.92143068e-01 -6.43031001e-02 -5.37504181e-02\n",
      "  8.97608250e-02 -1.34542525e-01  5.80316968e-02  8.68189242e-03\n",
      " -1.04180746e-01  6.46408275e-02 -2.87191402e-02 -1.12109110e-01\n",
      "  3.75786155e-01 -1.12525813e-01 -7.68224299e-02 -2.43063182e-01\n",
      " -8.59607533e-02 -1.73819691e-01 -1.91132784e-01 -5.37690409e-02\n",
      "  1.19617291e-01 -8.29374492e-02 -4.54027317e-02  6.08594455e-02\n",
      " -2.02379283e-02 -8.61751661e-02 -1.99317262e-02 -1.51314318e-01\n",
      " -1.57840908e-01 -1.60522491e-03 -4.25990224e-02  1.20317906e-01\n",
      " -5.66324182e-02  3.96984629e-02 -4.78619896e-02 -8.01960826e-02\n",
      " -3.54666263e-02 -7.69035444e-02 -6.42876253e-02 -3.08689654e-01\n",
      "  2.26556897e-01  4.05272283e-02  1.55991942e-01  6.20780997e-02\n",
      "  1.46457508e-01 -8.12545493e-02 -7.91816786e-02 -7.33875632e-02\n",
      "  8.18730220e-02 -7.79907927e-02  3.79798263e-01 -1.28965437e-01\n",
      "  1.94463823e-02 -7.18932524e-02  3.16320688e-01  1.83533639e-01\n",
      "  8.84350762e-03 -3.82002853e-02  1.32843405e-01  1.49493799e-01\n",
      "  2.79057422e-03  1.42002895e-01  1.38417870e-01 -1.70455799e-01\n",
      "  5.97284883e-02 -5.09720780e-02 -2.08913773e-01 -1.79159753e-02\n",
      "  2.16881052e-01 -5.87030053e-01 -3.20306532e-02 -2.41553411e-04\n",
      " -1.61274746e-01  2.31321175e-02  1.94668286e-02 -6.78434875e-03\n",
      " -8.97978619e-02  1.58379242e-01 -5.12850694e-02  8.80876929e-02\n",
      " -1.51118666e-01  5.47820777e-02 -8.73479173e-02  5.65561466e-02\n",
      " -2.25299329e-01  2.92401046e-01  7.12783076e-03  1.57949433e-01\n",
      "  1.50169969e-01 -1.73611511e-02  3.75429844e-03 -1.02139115e-01]\n",
      "Vocab(count:4007343, index:80103)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors['increases'])\n",
    "print(word_vectors.vocab['_'])\n",
    "# for k in word_vectors.vocab.keys():\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4087446\n",
      "[ 5.75057864e-01  7.52782375e-02 -3.01809937e-01  1.01989359e-02\n",
      " -3.28983128e-01 -3.13937850e-02  6.51189238e-02 -1.40033633e-01\n",
      "  5.46455204e-01  1.05655245e-01 -5.59008531e-02 -3.08947384e-01\n",
      "  1.48965105e-01 -2.30761945e-01  1.62432060e-01  3.47166389e-01\n",
      "  1.78274699e-02  2.16196924e-01 -2.33157679e-01  1.75116267e-02\n",
      "  1.90005854e-01 -2.58263722e-02  3.54427963e-01 -9.64064226e-02\n",
      "  6.08074255e-02  6.34836440e-04  2.44468406e-01  4.54809636e-01\n",
      " -1.16582677e-01 -6.61844313e-02  1.06634788e-01 -1.33135706e-01\n",
      "  6.68184906e-02  4.18486178e-01  1.87044203e-01  4.02310371e-01\n",
      " -4.54130545e-02  3.69635940e-01 -2.86800236e-01 -1.83732420e-01\n",
      "  5.36106646e-01 -6.98395818e-02 -1.47025902e-02  1.05892718e-01\n",
      " -7.59536102e-02 -2.90077984e-01  4.18996289e-02  5.22052586e-01\n",
      "  3.80992472e-01 -2.62682699e-02  2.84932703e-02  2.50182487e-02\n",
      " -2.45723184e-02 -1.82328582e-01  1.48312569e-01 -4.10612971e-01\n",
      " -1.80383157e-02 -1.23839051e-01 -6.49206415e-02  1.05875485e-01\n",
      " -5.05968809e-01 -2.35844105e-01  1.57352000e-01  2.40820087e-02\n",
      " -1.48342833e-01 -2.17919320e-01 -7.53199607e-02  2.48359039e-01\n",
      "  3.56323421e-01  3.90106440e-01  1.63040638e-01  3.80131751e-01\n",
      " -3.45302314e-01  6.67245537e-02  5.29584110e-01  1.16606429e-01\n",
      " -1.81824058e-01 -6.66088521e-01 -1.16182692e-01  6.95340261e-02\n",
      " -4.51468863e-02 -1.75704032e-01 -2.52713680e-01 -3.71231437e-01\n",
      "  1.63548216e-01 -1.74588397e-01 -6.90443933e-01 -2.88214743e-01\n",
      " -2.03764066e-01  2.64536947e-01  2.16060624e-01  1.05098002e-01\n",
      "  9.73511022e-03  7.21761957e-02 -6.71930835e-02  3.57902586e-01\n",
      " -3.36640745e-01  3.18684757e-01 -2.33721025e-02  4.49359939e-02\n",
      " -8.57190713e-02  3.57214034e-01 -4.12082285e-01 -4.24440466e-02\n",
      " -1.59489691e-01 -5.15523314e-01 -2.77525932e-01 -1.07311472e-01\n",
      " -2.56834149e-01 -5.22287905e-01  2.16772139e-01 -8.49958658e-02\n",
      "  2.05511823e-01  2.73960859e-01  1.48504049e-01  3.03707451e-01\n",
      " -1.87590644e-02 -2.24937469e-01 -1.30537882e-01 -2.19171762e-01\n",
      " -4.70873892e-01  2.14385793e-01  3.54593635e-01 -2.56474376e-01\n",
      "  7.56632090e-01 -1.53286695e-01 -2.75688712e-02 -3.73297138e-03\n",
      "  5.12206890e-02 -1.60100505e-01  2.89163202e-01 -4.76200402e-01\n",
      " -2.93927193e-01  6.82277143e-01  1.33553103e-01 -2.86907494e-01\n",
      " -3.06930542e-01 -3.24731261e-01 -5.08824825e-01 -2.92323947e-01\n",
      "  3.83859873e-01 -1.58835985e-02  3.95768076e-01  1.70087457e-01\n",
      "  1.89003035e-01 -2.64707625e-01  2.49815419e-01  2.88793534e-01\n",
      " -1.11832209e-01 -2.92873830e-01 -2.30214119e-01  2.16857791e-01\n",
      "  2.00150818e-01 -1.95414752e-01 -1.81283697e-01  3.54753323e-02\n",
      "  1.09880835e-01 -1.15600238e-02  2.61278868e-01  2.51525849e-01\n",
      "  4.26405333e-02 -2.68551521e-02 -3.68820816e-01 -3.41872312e-02\n",
      "  3.86481822e-01 -2.34438092e-01  3.54340285e-01  1.74980819e-01\n",
      " -4.01722610e-01  3.46536338e-01  1.44291939e-02 -4.83727485e-01\n",
      "  8.44349936e-02  3.77032936e-01  3.83145660e-01 -2.30813593e-01\n",
      "  1.10988803e-01  5.82531393e-02 -2.90487140e-01 -3.57207745e-01\n",
      "  1.69907674e-01  1.87503621e-01 -1.37731269e-01 -2.94077337e-01\n",
      "  9.69372690e-01 -3.89075786e-01  3.74393947e-02  1.71594769e-01\n",
      " -3.29155058e-01  7.66026378e-02  1.78742066e-01  5.58201194e-01\n",
      " -6.94016367e-02 -5.75171113e-02  3.98608446e-02  2.38407582e-01\n",
      " -1.66249290e-01 -1.15690917e-01 -3.75340998e-01  8.36405233e-02]\n"
     ]
    }
   ],
   "source": [
    "print(emb_dim)\n",
    "print(word_vectors['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = E_vocabSizeTotal,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'encode_seq_embedding')\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = V_vocabSizeTotal,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'decode_seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "            tl.layers.set_name_reuse(True)\n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 3,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "        net_out = DenseLayer(net_rnn, n_units=V_vocabSizeTotal, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing embedding matrix and dictionaries\n",
      "  [TL] EmbeddingInputlayer embedding_layer: (5000, 200)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <tensorlayer.layers.EmbeddingInputlayer object at 0x000002100AC0A9B0> has invalid type <class 'tensorlayer.layers.EmbeddingInputlayer'>, must be a string or Tensor. (Can not convert a EmbeddingInputlayer into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 270\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    271\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2707\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2796\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[1;32m-> 2797\u001b[1;33m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[0;32m   2798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a EmbeddingInputlayer into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-42c16173121a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# tl.files.assign_params(sess, [load_params[0]], emb_net)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0memb_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    272\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    273\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument <tensorlayer.layers.EmbeddingInputlayer object at 0x000002100AC0A9B0> has invalid type <class 'tensorlayer.layers.EmbeddingInputlayer'>, must be a string or Tensor. (Can not convert a EmbeddingInputlayer into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "## Step 1: Build the embedding matrix and load the existing embedding matrix.\n",
    "vocabulary_size = 5000\n",
    "embedding_size = 200\n",
    "\n",
    "print(\"Load existing embedding matrix and dictionaries\")\n",
    "\n",
    "x = tf.placeholder(tf.int32)\n",
    "\n",
    "emb_net = tl.layers.EmbeddingInputlayer(\n",
    "                inputs = x,\n",
    "                vocabulary_size = vocabulary_size,\n",
    "                embedding_size = embedding_size,\n",
    "                name ='embedding_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param   0: embedding_layer/embeddings:0 (5000, 200)        float32_ref (mean: 8.860853995429352e-05, median: -7.748603820800781e-06, std: 0.05772264301776886)   \n",
      "  num of params: 1000000\n",
      "  layer   0: embedding_layer/embedding_lookup:0 <unknown>          float32\n",
      "vector: (2, 200)\n",
      "[[-0.0814091  -0.02825403 -0.05328007 -0.02780311 -0.0653923  -0.02430246\n",
      "   0.01921391  0.09056108 -0.09929579 -0.04090867 -0.01154137  0.09985436\n",
      "  -0.01916699 -0.00505853  0.04639273 -0.0912411   0.05427978 -0.09722042\n",
      "  -0.00647257  0.08200861  0.02909157 -0.04913936 -0.02959277 -0.0851137\n",
      "   0.00671704  0.09491635 -0.05910125  0.091788   -0.06434856  0.06943984\n",
      "  -0.04222007  0.07136836 -0.01448791  0.08609817  0.00808146  0.03219343\n",
      "   0.04411275  0.09080558 -0.03130624 -0.00718544  0.08492801  0.07755976\n",
      "   0.00010915 -0.04611282 -0.00340497  0.07246631  0.03042834 -0.06478818\n",
      "  -0.01676147 -0.09139509 -0.01971438  0.09120715 -0.07756324 -0.06961818\n",
      "   0.03664833  0.02337506  0.09040568  0.00635266 -0.0232677   0.05131922\n",
      "  -0.00828378 -0.01890366  0.06180627 -0.06814513 -0.08772276  0.04930117\n",
      "  -0.00804181 -0.04816544 -0.02040946 -0.03723578  0.07128019  0.03358342\n",
      "   0.00175945 -0.02590559  0.06626294 -0.02632751 -0.01080777  0.06166667\n",
      "   0.01842217  0.09664319  0.06897724 -0.03472135  0.03253455  0.08549\n",
      "  -0.0626477  -0.071293    0.05145519 -0.02030382 -0.06248679  0.06851809\n",
      "  -0.08399463  0.04801769 -0.02574372 -0.02769997 -0.07764652  0.01641035\n",
      "  -0.03789518  0.07727473 -0.00599911  0.03927872  0.09613699  0.07379954\n",
      "  -0.02546068 -0.02422182  0.03840404 -0.05792975  0.08899603 -0.0242872\n",
      "  -0.01208117  0.04193506  0.0466134  -0.00183616 -0.02659454 -0.05663202\n",
      "  -0.07311726 -0.04884579 -0.05285804  0.01320484  0.02943525  0.04767544\n",
      "  -0.04150379  0.04774421 -0.05702195  0.06494596  0.00429349  0.0283756\n",
      "   0.09109474 -0.0475939  -0.07945001  0.06320525  0.06294789 -0.01478086\n",
      "   0.01389126 -0.09139919 -0.07270155  0.08053074 -0.07187185  0.02230828\n",
      "  -0.06168561  0.05019607  0.07826624 -0.02464239 -0.0066149  -0.03240955\n",
      "  -0.00385229 -0.04082232  0.08280382  0.08113091  0.05908503  0.04457793\n",
      "   0.03791159 -0.05727065  0.07495577 -0.07586212  0.01279597 -0.01022656\n",
      "  -0.09589694  0.07789364 -0.09572859 -0.01214912  0.07901294  0.08805538\n",
      "  -0.04041016  0.07057705  0.08430853  0.08616345  0.03034756  0.00775909\n",
      "  -0.01162942 -0.04242444  0.0576852   0.06635147 -0.03459122  0.09529198\n",
      "   0.08264447 -0.00417671  0.0068717  -0.02541959 -0.00895784  0.05633502\n",
      "  -0.02023423 -0.03201754  0.05500247 -0.07538845 -0.05355556  0.05799859\n",
      "   0.04012611 -0.00756764  0.01735234 -0.05125139  0.05509795 -0.05667336\n",
      "   0.02523936 -0.0846457   0.05294753 -0.08508065  0.06113666  0.06722381\n",
      "   0.09179395  0.02792025]\n",
      " [-0.07300625 -0.07178338  0.03270917  0.02948902 -0.0277539   0.06138358\n",
      "   0.01017196  0.05118606  0.07188684  0.00764177  0.03073985  0.01912494\n",
      "  -0.0554651   0.09886403  0.05280008 -0.07176642 -0.01712229  0.04176099\n",
      "   0.08187693 -0.04940658  0.04932959 -0.08736575  0.00255685 -0.05939186\n",
      "   0.07234604  0.07320827  0.09319598  0.00945397 -0.06233375  0.09591132\n",
      "  -0.08581748  0.07480397  0.07413114 -0.07826877  0.06565262  0.07895332\n",
      "  -0.01523657  0.00368941  0.09828029 -0.07414506 -0.03695448  0.08246288\n",
      "  -0.04058111 -0.07034735  0.09547866  0.08615381  0.05937629  0.08408075\n",
      "  -0.0946728  -0.071436   -0.03142031 -0.05875225  0.03170896 -0.03995001\n",
      "  -0.05601905 -0.01631327  0.05138335  0.04079201 -0.02838822  0.01236143\n",
      "   0.02981863 -0.07603975 -0.09796383 -0.03586268  0.04894937 -0.08194108\n",
      "  -0.03211312  0.08084717  0.06780542  0.0815691   0.08265116  0.0399312\n",
      "   0.09664    -0.04039614  0.03961148  0.06069844 -0.03849268 -0.03772125\n",
      "   0.02506114 -0.06698456 -0.09672111 -0.04906936 -0.02565558 -0.09466188\n",
      "   0.02353255  0.03603256 -0.0246475  -0.01452675 -0.00609956  0.01105201\n",
      "   0.09204819  0.06644251  0.06744719  0.08946664 -0.06974413 -0.09007275\n",
      "  -0.09396081  0.08545353  0.05483625  0.0232409   0.02502979  0.06613901\n",
      "  -0.05347154 -0.0361017  -0.06437609 -0.09312048  0.09458341 -0.07405777\n",
      "  -0.04676099  0.08480825 -0.08298071  0.020889   -0.07577868 -0.09467714\n",
      "  -0.01385655 -0.0227139   0.0305594   0.08777613  0.02581833  0.08205888\n",
      "   0.03562503 -0.06550424  0.07668728  0.05511682  0.05298973  0.05726523\n",
      "   0.04314273  0.04790816  0.02070372 -0.03391834 -0.09062868  0.09224934\n",
      "  -0.080515    0.09436899 -0.06191218 -0.07492499 -0.089097   -0.06039946\n",
      "   0.03624525  0.03962327 -0.00243914  0.07183299  0.06922155 -0.03958762\n",
      "  -0.01138282 -0.03288285  0.09082942  0.07501061  0.08312655 -0.07457254\n",
      "  -0.05529845  0.0806495  -0.07204566 -0.06080637  0.03589792  0.03760848\n",
      "   0.07028156 -0.04214993 -0.025786   -0.02254999  0.07231285  0.06653474\n",
      "   0.09377065  0.0376678  -0.06156909  0.02581067  0.06655353  0.08348911\n",
      "   0.0017391  -0.03146541 -0.07708132  0.09916549  0.01593781 -0.05660055\n",
      "  -0.04595266  0.05953134 -0.05407255 -0.04759119 -0.08280241  0.00292838\n",
      "  -0.0047915   0.04714618  0.02449934 -0.0954896   0.03650897 -0.05131836\n",
      "  -0.04769087 -0.04874864 -0.07176153  0.07729378  0.08030932  0.04159778\n",
      "   0.06162589 -0.05630584 -0.07728694 -0.02744737 -0.04501798 -0.02628002\n",
      "  -0.05703549 -0.04510691]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# sess.run(tf.initialize_all_variables())\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "\n",
    "# tl.files.assign_params(sess, [load_params[0]], emb_net)\n",
    "# print(sess.run(emb_net, {x:[1000, 1200]}))\n",
    "\n",
    "emb_net.print_params()\n",
    "emb_net.print_layers()\n",
    "\n",
    "vector = sess.run(emb_net.outputs, feed_dict={x : [1000,122]})\n",
    "print('vector:', vector.shape)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Assign:0' shape=(5000, 200) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pretrained = np.array([np.array([i for _ in range(200)]) for i in range(5000)])\n",
    "tl.files.assign_params(sess, [embed_pretrained], emb_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: (2, 200)\n",
      "[[1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.]\n",
      " [ 122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.]]\n"
     ]
    }
   ],
   "source": [
    "vector = sess.run(emb_net.outputs, feed_dict={x : [1000,122]})\n",
    "print('vector:', vector.shape)\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

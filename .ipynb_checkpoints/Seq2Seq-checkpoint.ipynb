{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Successfully processed HGNCDictIndex--------\n",
      "No. Entities: 42463\n",
      "Index Information: Counter({1: 170542, 2: 2194, 3: 241, 4: 48, 5: 13, 6: 12, 7: 5, 8: 3, 1167: 1, 10: 1, 9: 1, 11: 1})\n",
      "--------Successfully processed ChEBIDictIndex--------\n",
      "No. Entities: 53905\n",
      "Index Information: Counter({1: 221524, 2: 7348, 3: 508, 4: 97, 5: 21, 6: 8, 7: 5, 8: 1})\n",
      "--------Successfully processed GOBPDictIndex--------\n",
      "No. Entities: 30662\n",
      "Index Information: Counter({1: 122846, 2: 583, 3: 91, 4: 14, 5: 4, 6: 3})\n",
      "--------Successfully processed MESHDictIndex--------\n",
      "No. Entities: 4782\n",
      "Index Information: Counter({1: 53615})\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv, re, copy\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import *\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from Dictionary import *\n",
    "from nltk.tree import Tree\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentences(filename):\n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    sentences = [row for row in reader]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadAllTextSentences():\n",
    "    sentences = loadSentences('dataset/Training.sentence')\n",
    "    sentences.extend(loadSentences('dataset/SampleSet.sentence'))\n",
    "    sentences.extend(loadSentences('dataset/Task1NeuV3_corrected.sentence'))\n",
    "    # print(len(sentences))\n",
    "    TextSentenceID = dict()\n",
    "    vocabulary = set()\n",
    "    for line in sentences:\n",
    "        id = line['Sentence-ID'][4:]\n",
    "        text = line['Sentence']\n",
    "        output = nlp.annotate(text, properties={'annotators': 'tokenize', 'outputFormat': 'json'})\n",
    "#         print('---------------------------------------------')\n",
    "        if id not in TextSentenceID:\n",
    "            TextSentenceID[id] = {'id': id,\n",
    "                                  'text': text,\n",
    "                                  'pmid': line['PMID'],\n",
    "                                  'tokens': [i['originalText'] for i in output['tokens']]}\n",
    "            vocabulary = vocabulary.union(set(TextSentenceID[id]['tokens']))\n",
    "    #     else:\n",
    "    #         assert (TextSentenceID[id]['text'] == line['Sentence']), 'ID: %s \\n Text1: %s \\n Text2: %s'%(id, TextSentenceID[id]['text'], line['Sentence']) \n",
    "    #         assert (TextSentenceID[id]['pmid'] == line['PMID']), 'ID: %s \\n PMID1: %s \\n PMID2: %s'%(id, TextSentenceID[id]['pmid'], line['PMID'])\n",
    "    print('Download text sentences:', len(TextSentenceID), 'sentences')\n",
    "    # print(TextSentenceID['10000072']) \n",
    "    # {'id': '10000072', 'text': 'it was found that a 6-fold increase in Fdft1 activity compared with that of the wild-type did not cause significant changes in HmgCoA reductase activity, while the amounts of synthesized dolichols and ergosterols increased by 80 and 32 percent respectively.', 'pmid': '10623644'}\n",
    "    return TextSentenceID, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output = nlp.annotate('Hello World (This world!)', properties={'annotators': 'tokenize', 'outputFormat': 'json'})\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokeniseBEL(bs, mapToHGNC = False):\n",
    "    bs = re.subn(r',GOCCID:\\d+', '', bs) # Replace GOCCID (additional parameters of tloc)\n",
    "    bs = re.subn(r',sub\\([\\w,]*?\\)', '', bs[0]) # Remove all sub(_,_,_)\n",
    "    bs = re.subn(r',trunc\\(\\d+\\)', '', bs[0]) # Remove all trunc(_)\n",
    "    terms = re.findall(r'(a|bp|path|g|m|r|p)\\(([A-Z]+)\\:([^\"]*?|\".*?\")(,pmod\\(.*?\\))?\\)', bs[0])\n",
    "    # print(terms)\n",
    "    bs = re.subn(r'(a|bp|path|g|m|r|p)\\(([A-Z]+)\\:([^\"]*?|\".*?\")(,pmod\\(.*?\\))?\\)', '@', bs[0])\n",
    "    assert bs[1] == len(terms)\n",
    "    # print(bs)\n",
    "    relations = re.findall(r'\\s((?:->)|(?:-\\|)|(?:increases)|(?:decreases)|(?:directlyIncreases)|(?:directlyDecreases))\\s', bs[0])\n",
    "    # print(relations)\n",
    "    bs = re.subn(r'\\s((?:->)|(?:-\\|)|(?:increases)|(?:decreases)|(?:directlyIncreases)|(?:directlyDecreases))\\s', '&', bs[0])\n",
    "    assert bs[1] == len(relations)\n",
    "    # print(bs)\n",
    "    functions = re.findall(r'((?:act)|(?:complex)|(?:tloc)|(?:deg)|(?:kin)|(?:tscript)|(?:cat)|(?:sec)|(?:chap)|(?:gtp)|(?:pep)|(?:phos)|(?:ribo)|(?:tport)|(?:surf))', bs[0])\n",
    "    # print(functions)\n",
    "    bs = re.subn(r'((?:act)|(?:complex)|(?:tloc)|(?:deg)|(?:kin)|(?:tscript)|(?:cat)|(?:sec)|(?:chap)|(?:gtp)|(?:pep)|(?:phos)|(?:ribo)|(?:tport)|(?:surf))', '$', bs[0])\n",
    "    assert bs[1] == len(functions)\n",
    "    # print(bs[0]) # Term = @, Function = $, Relation = &\n",
    "    bs = re.subn(r', ', ',', bs[0]) # Remove white space after comma\n",
    "    template = bs[0]\n",
    "    return stringToTokens(template, terms, relations, functions, mapToHGNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stringToTokens(template, terms, relations, functions, mapToHGNC = False):\n",
    "    aList = []\n",
    "    typeDict = {'p':'p', 'bp':'bp', 'path':'path', 'a':'a', 'g':'p', 'm':'p', 'r':'p'}\n",
    "    relationDict = {'->': ' -> ', '-|': ' -| ', 'increases':' -> ', 'decreases':' -| ', 'directlyIncreases':' -> ', 'directlyDecreases':' -| '}\n",
    "    functionDict = {'act':'act', 'kin':'act', 'tscript':'act', 'cat':'act', 'chap':'act', 'gtp':'act', 'pep':'act', 'phos':'act', 'ribo':'act', 'tport':'act',\n",
    "                    'complex':'complex', \n",
    "                    'tloc': 'tloc', 'sec':'tloc', 'surf':'tloc', \n",
    "                    'deg': 'deg'}\n",
    "    for s in template:\n",
    "        if s == '@': # Term\n",
    "            termTuple = terms.pop(0)\n",
    "            ns = termTuple[1]\n",
    "            symbol = termTuple[2]\n",
    "            if mapToHGNC:\n",
    "                if ns == 'EGID': # Transform namespace (EGID to HGNC)\n",
    "                    if symbol in EGID2HGNC:\n",
    "                        ns = 'HGNC'\n",
    "                        symbol = EGID2HGNC[symbol]\n",
    "                        if any([a in symbol for a in [' ', '(', ')', '+', '-']]):\n",
    "                            symbol = '\"' + symbol + '\"'\n",
    "                    else:\n",
    "                        return False\n",
    "                elif ns == 'MGI': # Transform namespace (MGI to HGNC)\n",
    "                    if symbol in MGI2HGNC:\n",
    "                        ns = 'HGNC'\n",
    "                        symbol = MGI2HGNC[symbol]\n",
    "                        if any([a in symbol for a in [' ', '(', ')', '+', '-']]):\n",
    "                            symbol = '\"' + symbol + '\"'\n",
    "                    else:\n",
    "                        return False\n",
    "            if termTuple[3] == '':\n",
    "                aList.extend([typeDict[termTuple[0]], '(', ns+':'+symbol, ')'])\n",
    "            else:\n",
    "                aList.extend([typeDict[termTuple[0]], '(', ns+':'+symbol, ',', 'pmod(P)', ')'])\n",
    "        elif s == '&': # Relation\n",
    "            aList.append(relationDict[relations.pop(0)])\n",
    "        elif s == '$': # Function\n",
    "            aList.append(functionDict[functions.pop(0)])\n",
    "        else: # brackets and comma\n",
    "            aList.append(s)\n",
    "    return aList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download text sentences: 6536 sentences\n",
      "{'id': '10000072', 'text': 'it was found that a 6-fold increase in Fdft1 activity compared with that of the wild-type did not cause significant changes in HmgCoA reductase activity, while the amounts of synthesized dolichols and ergosterols increased by 80 and 32 percent respectively.', 'pmid': '10623644', 'tokens': ['it', 'was', 'found', 'that', 'a', '6-fold', 'increase', 'in', 'Fdft1', 'activity', 'compared', 'with', 'that', 'of', 'the', 'wild-type', 'did', 'not', 'cause', 'significant', 'changes', 'in', 'HmgCoA', 'reductase', 'activity', ',', 'while', 'the', 'amounts', 'of', 'synthesized', 'dolichols', 'and', 'ergosterols', 'increased', 'by', '80', 'and', '32', 'percent', 'respectively', '.']}\n",
      "19049\n"
     ]
    }
   ],
   "source": [
    "TextSentenceID, vocabulary = loadAllTextSentences()\n",
    "print(TextSentenceID['10000072'])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.25327557e-01 -2.05734119e-01  2.20678654e-02  1.27095148e-01\n",
      "  4.70568202e-02  3.66582334e-01  1.80289820e-01 -6.96827620e-02\n",
      "  5.25160849e-01  2.50934307e-02  1.86377347e-01 -1.57668844e-01\n",
      "  5.11006951e-01  2.82196283e-01 -1.45905316e-01 -1.02183104e-01\n",
      " -1.58878171e-03 -2.69769728e-01  4.36125807e-02 -3.74512225e-02\n",
      "  1.44765481e-01 -1.72953263e-01  5.64784929e-02  2.03118950e-01\n",
      " -2.29118302e-01 -3.89206707e-01  1.89598396e-01  8.48720893e-02\n",
      " -2.92850465e-01 -1.89046666e-01  3.03188503e-01 -4.85944226e-02\n",
      "  2.32507274e-01  1.78006619e-01  9.79960859e-02  6.02323450e-02\n",
      "  1.65033221e-01 -3.79372507e-01  1.18517898e-01 -1.47823170e-01\n",
      "  1.21478774e-01 -2.50081658e-01  2.41490863e-02  1.28086820e-01\n",
      "  3.87153685e-01 -1.73163749e-02 -1.84716210e-01 -2.07878187e-01\n",
      "  9.35073644e-02  3.20446283e-01  6.42037690e-02 -4.05614406e-01\n",
      "  7.49878660e-02 -1.26757715e-02  1.44438535e-01 -3.08646530e-01\n",
      "  1.06738694e-02  2.82481462e-01 -2.62360632e-01 -2.80956089e-01\n",
      " -1.86210290e-01 -1.15877595e-02 -1.58727970e-02 -1.02932915e-01\n",
      "  3.61133039e-01 -8.23537931e-02 -2.83741858e-03  5.16191423e-02\n",
      " -4.18368340e-01 -1.50543869e-01  2.32713625e-01  1.58457551e-02\n",
      "  7.49532357e-02 -2.56549895e-01  3.43764037e-01  2.38093615e-01\n",
      " -4.25283492e-01 -1.25486001e-01  1.66954264e-01  4.11511660e-02\n",
      " -1.69186573e-02 -1.92248717e-01  3.99735570e-01 -1.94719046e-01\n",
      " -2.46572997e-02  1.49890766e-01  4.76957671e-02  3.81951362e-01\n",
      "  1.08876072e-01  2.77450144e-01 -2.29126096e-01  2.58556068e-01\n",
      " -4.57857177e-02  5.42829782e-02 -1.10890254e-01 -2.01238692e-01\n",
      "  1.17767565e-01 -3.11075300e-01 -2.99588665e-02 -1.47615382e-02\n",
      "  4.28586006e-01  4.25316632e-01  1.92770615e-01 -5.87228499e-03\n",
      "  8.98397528e-03 -1.76456189e-04 -1.32660881e-01 -2.93322261e-02\n",
      " -1.97634950e-01  1.88606381e-01  7.76417330e-02 -1.28206015e-01\n",
      "  5.40913865e-02 -3.86624575e-01  4.84502800e-02 -5.41283712e-02\n",
      " -2.43484527e-01  4.76339050e-02  3.32977958e-02 -1.33472949e-01\n",
      "  5.08810759e-01 -2.07310498e-01 -2.18785211e-01 -2.15726122e-01\n",
      " -2.37135991e-01 -1.21456228e-01 -9.52737182e-02 -2.20923349e-01\n",
      "  1.73350364e-01  1.73229873e-01 -1.97473794e-01  1.51687950e-01\n",
      " -2.95273393e-01  1.54850528e-01 -5.90961659e-03 -1.79703921e-01\n",
      " -5.72281480e-02  1.62768081e-01  1.81678291e-02 -1.77953675e-01\n",
      " -2.27385700e-01 -3.52959707e-02  1.82563767e-01 -1.61678255e-01\n",
      "  4.25200760e-02  9.31143686e-02 -3.57891917e-01 -3.55402052e-01\n",
      " -2.97917217e-01  9.88947228e-02  2.28375435e-01  5.32136083e-01\n",
      "  3.74176502e-02 -3.60787958e-01 -1.39900863e-01  1.00078294e-03\n",
      " -9.83410925e-02 -1.41357124e-01  2.20851153e-01 -1.13046043e-01\n",
      "  4.87643667e-03 -1.32825494e-01  3.95833731e-01 -1.83650386e-02\n",
      "  1.80350214e-01  2.15704367e-01  5.28760105e-02  1.05752304e-01\n",
      "  2.86088765e-01  4.28989083e-01  1.75798118e-01  1.41190872e-01\n",
      "  2.28342578e-01 -2.38321200e-01 -2.94696212e-01  7.83535987e-02\n",
      "  1.20306291e-01 -2.19977051e-01 -6.22638948e-02 -1.18336909e-01\n",
      " -3.01841293e-02 -1.91611070e-02  2.57388890e-01  3.80244777e-02\n",
      " -8.39182809e-02  2.82942861e-01  9.14376304e-02  1.25304610e-01\n",
      " -1.01024613e-01 -1.06362179e-01  8.64111558e-02  9.60571133e-03\n",
      " -1.11674331e-01  3.23287606e-01  2.64685571e-01  3.73143911e-01\n",
      "  2.59604715e-02 -5.62201403e-02  7.41463751e-02 -9.38247368e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('word_embeddings/PubMed-and-PMC-w2v.bin', binary=True)\n",
    "print(word_vectors['Increases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emb_dim = 200\n",
    "T_vocab_size = 50000\n",
    "T_idx2w = ['_', 'unk'] + list(vocabulary) \n",
    "for word in word_vectors.vocab.keys():\n",
    "    if word not in T_idx2w:\n",
    "        T_idx2w.append(word)\n",
    "    if len(T_idx2w) >= T_vocab_size + 2:\n",
    "        break\n",
    "T_idx2w.extend(['start_id', 'end_id'])\n",
    "T_w2idx = dict([(T_idx2w[i], i) for i in range(len(T_idx2w))])\n",
    "T_vocab_size_total = len(T_idx2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = pickle.load(open(\"word_embedding.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = np.random.uniform(-0.1, 0.1, (2, emb_dim))\n",
    "count = 2\n",
    "for i in range(2, T_vocab_size_total-2):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    if T_idx2w[i] in word_vectors.vocab:\n",
    "#         print(word_embedding.shape, np.array([word_vectors[T_idx2w[i]]]).shape)\n",
    "        word_embedding = np.append(word_embedding, [word_vectors[T_idx2w[i]]], axis = 0)\n",
    "    else:\n",
    "        word_embedding = np.append(word_embedding, [np.random.uniform(-0.1, 0.1, emb_dim)], axis = 0)\n",
    "        count += 1\n",
    "word_embedding = np.append(word_embedding, [np.random.uniform(-0.1, 0.1, emb_dim)], axis = 0)\n",
    "word_embedding = np.append(word_embedding, [np.random.uniform(-0.1, 0.1, emb_dim)], axis = 0)\n",
    "print(word_embedding[T_w2idx['Increases']])\n",
    "print(count+2)\n",
    "pickle.dump(word_embedding, open(\"word_embedding.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50004, 200)\n"
     ]
    }
   ],
   "source": [
    "print(word_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03535113  0.03336161  0.1145009  -0.21139522  0.18536104  0.10084684\n",
      " -0.11079547  0.05809046  0.28275582  0.09770715  0.24691975  0.16967192\n",
      " -0.01673677  0.10089521 -0.1824921   0.14073035 -0.31860298 -0.41190234\n",
      " -0.13354068 -0.01240159 -0.18242343 -0.19114383  0.29078737 -0.17553619\n",
      "  0.12014313  0.01050218  0.04176245 -0.2670518   0.20612988  0.00271289\n",
      "  0.08800621  0.15186757 -0.10221786 -0.23187585  0.3860609   0.11735921\n",
      "  0.41534626 -0.00043791 -0.25374904 -0.13475522 -0.17009191 -0.24757084\n",
      "  0.2469786   0.30318278  0.03129166  0.02191979 -0.39349    -0.18328986\n",
      " -0.06172176 -0.20485361 -0.14117216  0.1620429   0.10013322  0.1703973\n",
      "  0.0057947   0.03997155  0.01984005  0.31967682  0.03971784 -0.06181415\n",
      " -0.16398661  0.03618234 -0.2556029   0.06158364  0.06112619 -0.09901944\n",
      "  0.04671043  0.02656536 -0.14078894 -0.30961394 -0.10270652  0.08510084\n",
      "  0.17530367  0.19034943 -0.03502771  0.3173125   0.16265504  0.04707861\n",
      " -0.26934457 -0.09730205  0.1446976  -0.05900989 -0.15005493  0.40760902\n",
      "  0.06786915  0.00106286  0.05675633  0.06854561 -0.22853696 -0.09870849\n",
      "  0.19731188 -0.00799766  0.02247702 -0.42282647 -0.11556686  0.22574368\n",
      " -0.11522113 -0.04546112  0.1301077   0.12825564 -0.28660494  0.02402923\n",
      " -0.2920041  -0.05757293  0.02417707 -0.14283693 -0.04422696 -0.00995797\n",
      "  0.01759223  0.06063282 -0.29632154 -0.2187702   0.31101707 -0.10137404\n",
      " -0.1710201  -0.13531926 -0.181882    0.23428924  0.01616936  0.07107998\n",
      "  0.23732218  0.07564197  0.25769502  0.03726544 -0.20136406 -0.19374196\n",
      " -0.02511327 -0.12885149 -0.35209078  0.03705822 -0.12476789  0.02720325\n",
      " -0.20342813  0.21221717 -0.04691553  0.18702842 -0.24304217 -0.36602542\n",
      " -0.03067977  0.3068114   0.05965139  0.23580624  0.08444382  0.2623039\n",
      " -0.20243165 -0.03855424 -0.11780781 -0.22667252 -0.01233976  0.23894423\n",
      "  0.29374692 -0.04962483 -0.07931887  0.23387513 -0.35191426  0.29733717\n",
      "  0.10614888  0.12687711  0.1225891  -0.23770748 -0.0222482  -0.2034795\n",
      "  0.3687666   0.28484556  0.3981272  -0.06430306  0.03890179  0.09467588\n",
      "  0.04900117  0.00697422 -0.00094434 -0.08924208 -0.15491135 -0.00046572\n",
      " -0.18971935  0.12177135 -0.00912365 -0.06477189 -0.04399572  0.19256975\n",
      " -0.19259314 -0.10304447 -0.39464125 -0.12147241 -0.12536184 -0.05182929\n",
      " -0.02198321 -0.02910924  0.02193753  0.26400977 -0.2941968   0.05520311\n",
      "  0.26402447  0.27014035 -0.17103481  0.23436265 -0.01516778  0.39200947\n",
      " -0.1017929   0.22384286]\n",
      "Vocab(count:4086555, index:891)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors['wild-type'])\n",
    "print(word_vectors.vocab['wild-type'])\n",
    "# for k in word_vectors.vocab.keys():\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', 'unk', '(', ')', ',', 'p', 'a', 'bp', 'path', 'act', 'pmod(P)', 'tloc', 'complex', 'deg', ' -> ', ' -| ', ' -- ', 'PH:placeholder', 'HGNC:A1BG', 'HGNC:\"A1BG-AS1\"', 'HGNC:A1CF', 'HGNC:A2M', 'HGNC:\"A2M-AS1\"', 'HGNC:A2ML1', 'HGNC:\"A2ML1-AS1\"', 'HGNC:\"A2ML1-AS2\"', 'HGNC:A2MP1', 'HGNC:A3GALT2', 'HGNC:A4GALT', 'HGNC:A4GNT', 'HGNC:A12M1', 'HGNC:A12M2', 'HGNC:A12M3', 'HGNC:A12M4', 'HGNC:AAAS', 'HGNC:AABT', 'HGNC:AACS', 'HGNC:AACSP1', 'HGNC:AADAC', 'HGNC:AADACL2', 'HGNC:\"AADACL2-AS1\"', 'HGNC:AADACL3', 'HGNC:AADACL4', 'HGNC:AADACP1', 'HGNC:AADAT', 'HGNC:AAED1', 'HGNC:AAGAB', 'HGNC:AAK1', 'HGNC:AAMDC', 'HGNC:AAMP', 'HGNC:AANAT', 'HGNC:AAR2', 'HGNC:AARD', 'HGNC:AARS', 'HGNC:AARS2', 'HGNC:AARSD1', 'HGNC:AARSP1', 'HGNC:AASDH', 'HGNC:AASDHPPT', 'HGNC:AASS', 'HGNC:AATBC', 'HGNC:AATF', 'HGNC:AATK', 'HGNC:AAVS1', 'HGNC:ABALON', 'HGNC:ABAT', 'HGNC:ABCA1', 'HGNC:ABCA2', 'HGNC:ABCA3', 'HGNC:ABCA4', 'HGNC:ABCA5', 'HGNC:ABCA6', 'HGNC:ABCA7', 'HGNC:ABCA8', 'HGNC:ABCA9', 'HGNC:\"ABCA9-AS1\"', 'HGNC:ABCA10', 'HGNC:ABCA11P', 'HGNC:ABCA12', 'HGNC:ABCA13', 'HGNC:ABCA17P', 'HGNC:ABCB1', 'HGNC:ABCB4', 'HGNC:ABCB5', 'HGNC:ABCB6', 'HGNC:ABCB7', 'HGNC:ABCB8', 'HGNC:ABCB9', 'HGNC:ABCB10', 'HGNC:ABCB10P1', 'HGNC:ABCB10P3', 'HGNC:ABCB10P4', 'HGNC:ABCB11', 'HGNC:ABCC1', 'HGNC:ABCC2', 'HGNC:ABCC3', 'HGNC:ABCC4', 'HGNC:ABCC5', 'HGNC:\"ABCC5-AS1\"', 'HGNC:ABCC6', 'HGNC:ABCC6P1', 'HGNC:ABCC6P2', 'HGNC:ABCC8', 'HGNC:ABCC9', 'HGNC:ABCC10', 'HGNC:ABCC11', 'HGNC:ABCC12', 'HGNC:ABCC13', 'HGNC:ABCD1', 'HGNC:ABCD1P1', 'HGNC:ABCD1P2', 'HGNC:ABCD1P3', 'HGNC:ABCD1P4', 'HGNC:ABCD1P5', 'HGNC:ABCD2', 'HGNC:ABCD3', 'HGNC:ABCD4', 'HGNC:ABCE1', 'HGNC:ABCF1', 'HGNC:\"ABCF1-DT\"', 'HGNC:ABCF2', 'HGNC:ABCF2P1', 'HGNC:ABCF2P2', 'HGNC:ABCF3', 'HGNC:ABCG1', 'HGNC:ABCG2', 'HGNC:ABCG4', 'HGNC:ABCG5', 'HGNC:ABCG8', 'HGNC:ABHD1', 'HGNC:ABHD2', 'HGNC:ABHD3', 'HGNC:ABHD4', 'HGNC:ABHD5', 'HGNC:ABHD6', 'HGNC:ABHD8', 'HGNC:ABHD10', 'HGNC:ABHD11', 'HGNC:\"ABHD11-AS1\"', 'HGNC:\"ABHD11-AS2\"', 'HGNC:ABHD12', 'HGNC:ABHD12B', 'HGNC:ABHD13', 'HGNC:ABHD14A', 'HGNC:\"ABHD14A-ACY1\"', 'HGNC:ABHD14B', 'HGNC:ABHD15', 'HGNC:\"ABHD15-AS1\"', 'HGNC:ABHD16A', 'HGNC:ABHD16B', 'HGNC:ABHD17A', 'HGNC:ABHD17AP1', 'HGNC:ABHD17AP3', 'HGNC:ABHD17AP4', 'HGNC:ABHD17AP5', 'HGNC:ABHD17AP6', 'HGNC:ABHD17AP7', 'HGNC:ABHD17AP8', 'HGNC:ABHD17AP9', 'HGNC:ABHD17B', 'HGNC:ABHD17C', 'HGNC:ABHD18', 'HGNC:ABI1', 'HGNC:ABI1P1', 'HGNC:ABI2', 'HGNC:ABI3', 'HGNC:ABI3BP', 'HGNC:ABL1', 'HGNC:ABL2', 'HGNC:ABLIM1', 'HGNC:ABLIM2', 'HGNC:ABLIM3', 'HGNC:ABO', 'HGNC:ABR', 'HGNC:ABRA', 'HGNC:ABRACL', 'HGNC:ABRAXAS1', 'HGNC:ABRAXAS2', 'HGNC:ABT1', 'HGNC:ABT1P1', 'HGNC:ABTB1', 'HGNC:ABTB2', 'HGNC:ACAA1', 'HGNC:ACAA2', 'HGNC:ACACA', 'HGNC:ACACB', 'HGNC:ACAD', 'HGNC:ACAD8', 'HGNC:ACAD9', 'HGNC:ACAD10', 'HGNC:ACAD11', 'HGNC:ACADL', 'HGNC:ACADM', 'HGNC:ACADS', 'HGNC:ACADSB', 'HGNC:ACADVL', 'HGNC:ACAN', 'HGNC:ACAP1', 'HGNC:ACAP2', 'HGNC:\"ACAP2-IT1\"']\n",
      "131832\n"
     ]
    }
   ],
   "source": [
    "B_idx2w = ['_', 'unk', '(', ')', ',', 'p', 'a', 'bp', 'path', 'act', 'pmod(P)', 'tloc', 'complex', 'deg', ' -> ', ' -| ', ' -- ', 'PH:placeholder']\n",
    "B_idx2w.extend(['HGNC:'+x if all([a not in x for a in [' ', '(', ')', '+', '-']]) else 'HGNC:\"'+x+'\"' for x in HGNCDict.keys()])\n",
    "B_idx2w.extend(['CHEBI:'+x if all([a not in x for a in [' ', '(', ')', '+', '-']]) else 'CHEBI:\"'+x+'\"' for x in ChEBIDict.keys()])\n",
    "B_idx2w.extend(['GOBP:'+x if all([a not in x for a in [' ', '(', ')', '+', '-']]) else 'GOBP:\"'+x+'\"' for x in GOBPDict.keys()])\n",
    "B_idx2w.extend(['MESHD:'+x if all([a not in x for a in [' ', '(', ')', '+', '-']]) else 'MESHD:\"'+x+'\"' for x in MESHDict.keys()])\n",
    "B_idx2w.extend(['start_id', 'end_id'])\n",
    "B_w2idx = dict([(B_idx2w[i], i) for i in range(len(B_idx2w))])\n",
    "B_vocab_size_total = len(B_idx2w)\n",
    "print(B_idx2w[:200])\n",
    "print(B_vocab_size_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = loadSentences('dataset/TrainingNormalised.BEL')\n",
    "# trainBSentences = [line['BEL-normalised'] for line in sentences]\n",
    "# trainBTokenized = [tokeniseBEL(line) for line in trainBSentences]\n",
    "# trainTSentences = [TextSentenceID[line['Sentence-ID'][4:]]['text'] for line in sentences]\n",
    "# trainTTokenized = [TextSentenceID[line['Sentence-ID'][4:]]['tokens'] for line in sentences]\n",
    "# assert len(trainBTokenized) == len(trainTTokenized)\n",
    "# print(trainBTokenized[150], trainTTokenized[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words2index(listOfWords, w2idx):\n",
    "    lst = []\n",
    "    for w in listOfWords:\n",
    "        if w in w2idx:\n",
    "            lst.append(w2idx[w])\n",
    "        else:\n",
    "            lst.append(w2idx['unk'])\n",
    "#             print(listOfWords)\n",
    "            if ' -> ' in w2idx:\n",
    "                print('Word in BEL converted to unknown:', w)\n",
    "            else:\n",
    "                print('Word in Text converted to unknown:', w)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainT = [words2index(sublist, T_w2idx) for sublist in trainTTokenized]\n",
    "# trainB = [words2index(sublist, B_w2idx) for sublist in trainBTokenized]\n",
    "# print(trainB[150], trainT[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted BEL sentence: a(CHEBI:corticotropin) -> p(MGI:Sik1,pmod(P))\n",
      "Deleted BEL sentence: act(p(EGID:12534)) -> p(HGNC:BTG1,pmod(P))\n",
      "Deleted BEL sentence: act(p(EGID:279561)) -> p(HGNC:SLC12A4,pmod(P))\n",
      "Deleted BEL sentence: act(p(EGID:279561)) -> p(HGNC:SLC12A4,pmod(P))\n",
      "Deleted BEL sentence: act(p(MGI:Adrbk2)) -> p(HGNC:OPRK1,pmod(P))\n",
      "Deleted BEL sentence: act(p(HGNC:SRPK1)) -> p(EGID:110809,pmod(P))\n",
      "Deleted BEL sentence: act(p(HGNC:SRPK2)) -> p(EGID:110809,pmod(P))\n",
      "Deleted BEL sentence: act(p(HGNC:TSSK6)) -> p(MGI:H3f3a,pmod(P))\n",
      "Deleted BEL sentence: p(EGID:103968,pmod(P)) -> act(p(HGNC:PNPLA2))\n",
      "Deleted BEL sentence: act(p(MGI:Ppp1cc)) -| p(HGNC:EIF2S1,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Cdc42) -| p(HGNC:AXIN1,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Cdc42) -> p(HGNC:GSK3B,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Il3) -> p(HGNC:BCL2,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Il3) -> p(HGNC:CRKL,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Irs3) -| p(HGNC:IRS1,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Irs3) -| p(HGNC:IRS2,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Irs4) -| p(HGNC:IRS1,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Irs4) -| p(HGNC:IRS2,pmod(P))\n",
      "Deleted BEL sentence: p(HGNC:RELA,pmod(P)) -| p(MGI:\"Rela\",pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Sik1,pmod(P)) -| tloc(p(MGI:Sik1))\n",
      "Deleted BEL sentence: a(CHEBI:\"carbon monoxide\") -> p(MGI:Hspa1b)\n",
      "Deleted BEL sentence: a(CHEBI:indometacin) -| act(p(MGI:Cyp2d9))\n",
      "Deleted BEL sentence: a(CHEBI:indometacin) -| act(p(MGI:Cyp3a11))\n",
      "Deleted BEL sentence: a(CHEBI:\"lipoteichoic acid\") -> p(MGI:Adrbk1)\n",
      "Deleted BEL sentence: a(CHEBI:trifluoperazine) -| act(p(MGI:Calm1))\n",
      "Deleted BEL sentence: bp(GOBP:\"response to endoplasmic reticulum stress\") -> complex(p(MGI:Atf1),p(HGNC:CREB1))\n",
      "Deleted BEL sentence: bp(GOBP:\"response to osmotic stress\") -> p(MGI:Hnrnpa1)\n",
      "Deleted BEL sentence: bp(GOBP:\"wound healing\") -> p(MGI:Ifna2)\n",
      "Deleted BEL sentence: act(p(EGID:104263)) -| act(p(HGNC:ETV2))\n",
      "Deleted BEL sentence: act(p(EGID:116816)) -> act(p(HGNC:MAPK1))\n",
      "Deleted BEL sentence: act(p(EGID:116816)) -> act(p(HGNC:MAPK3))\n",
      "Deleted BEL sentence: act(p(EGID:116817)) -> act(p(HGNC:MAPK1))\n",
      "Deleted BEL sentence: act(p(EGID:116817)) -> act(p(HGNC:MAPK3))\n",
      "Deleted BEL sentence: act(p(EGID:330914)) -| act(p(MGI:Cdc42))\n",
      "Deleted BEL sentence: act(p(EGID:330914)) -| act(p(MGI:Cdc42))\n",
      "Deleted BEL sentence: act(p(EGID:330914)) -| act(p(HGNC:RAC1))\n",
      "Deleted BEL sentence: act(p(HGNC:CAPN2)) -> act(p(MGI:Casp12))\n",
      "Deleted BEL sentence: act(p(MGI:Cbs)) -> act(p(HGNC:ACAA1))\n",
      "Deleted BEL sentence: act(p(HGNC:CCR1)) -| p(MGI:Ccl6)\n",
      "Deleted BEL sentence: act(p(HGNC:CD44)) -| p(MGI:\"mt-Co1\")\n",
      "Deleted BEL sentence: act(p(MGI:Gpr64)) -> bp(GOBP:spermatogenesis)\n",
      "Deleted BEL sentence: act(p(MGI:Gstp1)) -| act(p(HGNC:MAPK1))\n",
      "Deleted BEL sentence: act(p(MGI:Gstp1)) -| act(p(HGNC:MAPK3))\n",
      "Deleted BEL sentence: act(p(MGI:Gstp1)) -| act(p(HGNC:MAPK8))\n",
      "Deleted BEL sentence: act(p(HGNC:HELLS)) -| p(MGI:Cdkn1c)\n",
      "Deleted BEL sentence: act(p(HGNC:ITGAV)) -| p(EGID:12096)\n",
      "Deleted BEL sentence: act(p(HGNC:LIPE)) -> p(EGID:103968)\n",
      "Deleted BEL sentence: act(p(HGNC:MMP12)) -> deg(p(MGI:Eln))\n",
      "Deleted BEL sentence: act(p(MGI:\"mt-Co2\")) -> p(HGNC:C1QB)\n",
      "Deleted BEL sentence: act(p(MGI:Niacr1)) -| bp(GOBP:\"macrophage differentiation\")\n",
      "Deleted BEL sentence: act(p(MGI:Niacr1)) -| p(HGNC:ARG2)\n",
      "Deleted BEL sentence: act(p(MGI:Niacr1)) -> p(HGNC:ABCG1)\n",
      "Deleted BEL sentence: act(p(HGNC:SHH)) -| p(EGID:387202)\n",
      "Deleted BEL sentence: act(p(HGNC:CLGN)) -> complex(p(MGI:Adam1a),p(HGNC:ADAM2))\n",
      "Deleted BEL sentence: complex(p(MGI:Atf1),p(HGNC:CREB1)) -> p(HGNC:HSPA5)\n",
      "Deleted BEL sentence: complex(p(MGI:Ccnb1),p(HGNC:CDK2)) -> act(p(HGNC:CDK2))\n",
      "Deleted BEL sentence: complex(p(HGNC:CEBPB),p(HGNC:NFE2L1)) -| p(MGI:Dspp)\n",
      "Deleted BEL sentence: complex(p(MGI:\"H2-T23\"),p(HGNC:INS)) -> bp(GOBP:\"inflammatory response\")\n",
      "Deleted BEL sentence: complex(p(HGNC:IL12A),p(HGNC:IL12B)) -> p(MGI:Gzmg)\n",
      "Deleted BEL sentence: complex(p(HGNC:IL12B),p(HGNC:IL23A)) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: complex(p(HGNC:IL12B),p(HGNC:IL23A)) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: complex(p(MGI:Ins1),p(HGNC:INSR)) -> act(p(HGNC:INSR))\n",
      "Deleted BEL sentence: complex(p(MGI:Irs3),p(HGNC:PTPN11)) -> bp(GOBP:\"MAPK cascade\")\n",
      "Deleted BEL sentence: complex(p(MGI:Irs3),p(HGNC:PTPN11)) -> act(p(HGNC:PTPN11))\n",
      "Deleted BEL sentence: complex(p(HGNC:NFE2L1),p(HGNC:MAFG)) -> p(MGI:\"Hba-a1\")\n",
      "Deleted BEL sentence: complex(p(HGNC:NFE2L1),p(HGNC:MAFG)) -> p(MGI:\"Hbb-b1\")\n",
      "Deleted BEL sentence: complex(p(MGI:Serpinb1b),p(HGNC:CTSG)) -| act(p(HGNC:CTSG))\n",
      "Deleted BEL sentence: act(p(MGI:Cdc42)) -> act(p(HGNC:PRKCZ))\n",
      "Deleted BEL sentence: act(p(EGID:12534)) -> p(HGNC:MYCN,pmod(P))\n",
      "Deleted BEL sentence: act(p(EGID:279561)) -| act(p(HGNC:SLC12A4))\n",
      "Deleted BEL sentence: act(p(MGI:Adrbk1)) -> p(HGNC:SCNN1B,pmod(P))\n",
      "Deleted BEL sentence: act(p(MGI:Adrbk1)) -> act(p(HGNC:SCNN1B))\n",
      "Deleted BEL sentence: act(p(MGI:Adrbk2)) -| act(p(HGNC:OPRK1))\n",
      "Deleted BEL sentence: act(p(HGNC:AKT1)) -| p(MGI:Cdkn1c)\n",
      "Deleted BEL sentence: act(p(HGNC:CDK5)) -> act(p(EGID:18555))\n",
      "Deleted BEL sentence: act(p(HGNC:CDK5)) -> p(EGID:18555,pmod(P))\n",
      "Deleted BEL sentence: act(p(HGNC:EGFR)) -| p(MGI:Wfdc18)\n",
      "Deleted BEL sentence: act(p(HGNC:IKBKE)) -> p(MGI:Ifi203)\n",
      "Deleted BEL sentence: act(p(HGNC:IKBKE)) -> p(MGI:Ifi203)\n",
      "Deleted BEL sentence: act(p(HGNC:IKBKE)) -> p(MGI:Ifit3)\n",
      "Deleted BEL sentence: act(p(HGNC:MAPK8)) -> p(MGI:Ywhaq,pmod(P))\n",
      "Deleted BEL sentence: act(p(HGNC:NEK9)) -| p(MGI:Mup1)\n",
      "Deleted BEL sentence: act(p(HGNC:NEK9)) -| p(MGI:Mup2)\n",
      "Deleted BEL sentence: act(p(MGI:Sik1)) -| act(p(HGNC:CREB1))\n",
      "Deleted BEL sentence: act(p(HGNC:SRC)) -| p(EGID:665646)\n",
      "Deleted BEL sentence: act(p(HGNC:SRC)) -| p(MGI:Cox6c)\n",
      "Deleted BEL sentence: act(p(HGNC:WEE1)) -> p(EGID:12534,pmod(P))\n",
      "Deleted BEL sentence: p(MGI:Ifna1) -> act(p(HGNC:STAT1))\n",
      "Deleted BEL sentence: p(MGI:Ifna1) -> act(p(HGNC:STAT1))\n",
      "Deleted BEL sentence: p(EGID:12765) -> p(HGNC:CXCL10)\n",
      "Deleted BEL sentence: p(EGID:12765) -> p(MGI:Cxcl9)\n",
      "Deleted BEL sentence: p(EGID:12806) -| act(p(HGNC:IRF8))\n",
      "Deleted BEL sentence: p(EGID:19368) -> act(p(HGNC:CASP3))\n",
      "Deleted BEL sentence: p(EGID:19368) -> act(p(HGNC:CASP7))\n",
      "Deleted BEL sentence: p(EGID:19368) -> p(MGI:Gzmb)\n",
      "Deleted BEL sentence: p(HGNC:ADAM19) -> tloc(p(MGI:Nrg1))\n",
      "Deleted BEL sentence: p(HGNC:ADA) -| p(MGI:Ccl7)\n",
      "Deleted BEL sentence: p(HGNC:ADA) -| p(MGI:Ccl7)\n",
      "Deleted BEL sentence: p(HGNC:AK1) -| p(MGI:Gapdh)\n",
      "Deleted BEL sentence: p(MGI:Apoc3) -| act(p(HGNC:LPL))\n",
      "Deleted BEL sentence: p(HGNC:APOE) -> p(MGI:Mir143)\n",
      "Deleted BEL sentence: p(HGNC:APOE) -> p(MGI:Mir145)\n",
      "Deleted BEL sentence: p(HGNC:AREG) -| p(MGI:Cbs)\n",
      "Deleted BEL sentence: p(HGNC:BGN) -> p(EGID:12096)\n",
      "Deleted BEL sentence: p(MGI:Bhlhe41) -> complex(p(HGNC:CEBPB),p(HGNC:HDAC1))\n",
      "Deleted BEL sentence: p(MGI:Bhlhe41) -| act(p(HGNC:CEBPA))\n",
      "Deleted BEL sentence: p(MGI:Bhlhe41) -| act(p(HGNC:CEBPB))\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -> p(EGID:12096)\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -| p(EGID:12096)\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -> p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -| p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -> tloc(p(EGID:12096))\n",
      "Deleted BEL sentence: p(HGNC:BMP2) -> tloc(p(MGI:Bglap2))\n",
      "Deleted BEL sentence: p(MGI:Ccl19) -> act(p(HGNC:JAK3))\n",
      "Deleted BEL sentence: p(MGI:Ccl19) -> p(HGNC:CD40)\n",
      "Deleted BEL sentence: p(MGI:Ccl19) -> p(HGNC:CD86)\n",
      "Deleted BEL sentence: p(MGI:Ccl21a) -> act(p(HGNC:JAK3))\n",
      "Deleted BEL sentence: p(MGI:Cdc42) -> bp(GOBP:\"cell differentiation\")\n",
      "Deleted BEL sentence: p(MGI:Cdc42) -| deg(p(HGNC:CTNNB1))\n",
      "Deleted BEL sentence: p(MGI:Cdkn1c) -| bp(GOBP:\"cell proliferation\")\n",
      "Deleted BEL sentence: p(HGNC:CELA1) -> p(MGI:Eln)\n",
      "Deleted BEL sentence: p(HGNC:CELA1) -> p(MGI:Eln)\n",
      "Deleted BEL sentence: p(HGNC:CHRD) -| act(p(EGID:109899))\n",
      "Deleted BEL sentence: p(HGNC:CHRD) -| p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(MGI:Clca3) -| p(HGNC:BAX)\n",
      "Deleted BEL sentence: p(MGI:Clca3) -> p(HGNC:BCL2)\n",
      "Deleted BEL sentence: p(MGI:Cops2) -| p(HGNC:CCNE1)\n",
      "Deleted BEL sentence: p(MGI:Cops2) -| p(HGNC:CDKN1A)\n",
      "Deleted BEL sentence: p(MGI:Cops2) -| p(HGNC:TP53)\n",
      "Deleted BEL sentence: p(MGI:Cops2) -> tloc(p(HGNC:NIF3L1))\n",
      "Deleted BEL sentence: p(HGNC:CRY1) -> act(p(EGID:12534))\n",
      "Deleted BEL sentence: p(HGNC:CSF1) -> p(EGID:111785)\n",
      "Deleted BEL sentence: p(HGNC:CSF2) -> act(complex(p(HGNC:CSF2RA),p(MGI:Csf2rb)))\n",
      "Deleted BEL sentence: p(MGI:Cxcl11) -> bp(GOBP:\"T cell proliferation\")\n",
      "Deleted BEL sentence: p(MGI:Cxcl11) -| p(HGNC:COL1A1)\n",
      "Deleted BEL sentence: p(HGNC:CXCL2) -> act(p(EGID:12765))\n",
      "Deleted BEL sentence: p(HGNC:CXCL3) -> act(p(EGID:12765))\n",
      "Deleted BEL sentence: p(HGNC:CXCL3) -> act(p(EGID:12765))\n",
      "Deleted BEL sentence: p(MGI:Defb4) -> act(p(HGNC:TLR4))\n",
      "Deleted BEL sentence: p(HGNC:DLX3) -> p(EGID:109899)\n",
      "Deleted BEL sentence: p(HGNC:DLX3) -> p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(HGNC:DLX3) -> p(MGI:Esx1)\n",
      "Deleted BEL sentence: p(HGNC:DNAJA1) -| p(EGID:18617)\n",
      "Deleted BEL sentence: p(HGNC:DNAJA1) -| p(EGID:21753)\n",
      "Deleted BEL sentence: p(HGNC:EGF) -| p(EGID:104191)\n",
      "Deleted BEL sentence: p(HGNC:EGF) -| p(MGI:Wfdc18)\n",
      "Deleted BEL sentence: p(HGNC:EGR1) -> p(EGID:319520)\n",
      "Deleted BEL sentence: p(HGNC:FADD) -> p(MGI:Ifna2)\n",
      "Deleted BEL sentence: p(HGNC:FADD) -> p(MGI:Ifna4)\n",
      "Deleted BEL sentence: p(HGNC:FADD) -> p(MGI:Ifna5)\n",
      "Deleted BEL sentence: p(HGNC:FOXA2) -| p(MGI:Abcb1b)\n",
      "Deleted BEL sentence: p(HGNC:FOXM1) -> p(MGI:Ccnb1)\n",
      "Deleted BEL sentence: p(HGNC:GATA4) -> act(p(MGI:\"Nkx2-5\"))\n",
      "Deleted BEL sentence: p(HGNC:CSHL1) -> p(MGI:Serpina3k)\n",
      "Deleted BEL sentence: p(MGI:\"H2-T23\") -> bp(GOBP:\"T cell activation\")\n",
      "Deleted BEL sentence: p(HGNC:HFE) -> p(MGI:Hamp)\n",
      "Deleted BEL sentence: p(HGNC:HIF1A) -> p(MGI:Bnip3l)\n",
      "Deleted BEL sentence: p(HGNC:HIF1A) -> p(MGI:Retnla)\n",
      "Deleted BEL sentence: p(MGI:Hmgb1) -> bp(GOBP:\"neutrophil activation\")\n",
      "Deleted BEL sentence: p(MGI:Hmgb1) -> act(p(HGNC:TLR4))\n",
      "Deleted BEL sentence: p(MGI:Hmgb1) -> act(p(HGNC:AKT1))\n",
      "Deleted BEL sentence: p(MGI:Hmgb1) -> act(p(HGNC:IRAK4))\n",
      "Deleted BEL sentence: p(MGI:Hmgn3) -> p(HGNC:SLC2A2)\n",
      "Deleted BEL sentence: p(MGI:Hmgn3) -> p(HGNC:SLC2A2)\n",
      "Deleted BEL sentence: p(HGNC:HNF1A) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: p(MGI:Hnrnpa1) -> p(HGNC:CCND1)\n",
      "Deleted BEL sentence: p(MGI:Hnrnpa1) -> p(HGNC:MYC)\n",
      "Deleted BEL sentence: p(HGNC:HOXA13) -| p(MGI:Selenbp1)\n",
      "Deleted BEL sentence: p(HGNC:HP) -| tloc(p(MGI:Orm1))\n",
      "Deleted BEL sentence: p(MGI:Hrg) -| bp(GOBP:angiogenesis)\n",
      "Deleted BEL sentence: p(MGI:Hrg) -| bp(GOBP:\"cell proliferation\")\n",
      "Deleted BEL sentence: p(MGI:Hspa1a) -| path(MESHD:Hypertrophy)\n",
      "Deleted BEL sentence: p(MGI:Hspa1b) -> bp(GOBP:\"wound healing\")\n",
      "Deleted BEL sentence: p(MGI:Hspa1b) -| path(MESHD:Hypertrophy)\n",
      "Deleted BEL sentence: p(MGI:Hspa1b) -> p(HGNC:MAPK14)\n",
      "Deleted BEL sentence: p(MGI:Hspa1b) -> tloc(p(HGNC:TNF))\n",
      "Deleted BEL sentence: p(HGNC:HTT) -> p(EGID:15127)\n",
      "Deleted BEL sentence: p(HGNC:ID2) -> p(MGI:\"Hba-a1\")\n",
      "Deleted BEL sentence: p(MGI:Ifna1) -> p(MGI:\"H2-Ab1\")\n",
      "Deleted BEL sentence: p(HGNC:IFNAR1) -> p(MGI:Ifna1)\n",
      "Deleted BEL sentence: p(HGNC:IFNB1) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -| p(MGI:Ighg2b)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -| p(EGID:16020)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(EGID:380793)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -| p(MGI:Ighg1)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(EGID:15033)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(MGI:Gapdh)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(MGI:\"H2-Eb2\")\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(MGI:\"H2-T23\")\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> p(MGI:Ifi47)\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> surf(p(EGID:15033))\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> surf(p(MGI:\"H2-D1\"))\n",
      "Deleted BEL sentence: p(HGNC:IFNG) -> surf(p(MGI:\"H2-K1\"))\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Ccl7)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -| p(MGI:Serpina1a)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(EGID:20755)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(EGID:20755)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Ccl7)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Ccl8)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Clca3)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Clca3)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Muc1)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -| p(MGI:Serpina1a)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -| p(MGI:Serpina1a)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Sprr2b)\n",
      "Deleted BEL sentence: p(HGNC:IL13) -> p(MGI:Sprr2b)\n",
      "Deleted BEL sentence: p(HGNC:IL17F) -> p(MGI:Cxcl9)\n",
      "Deleted BEL sentence: p(HGNC:IL1B) -> p(MGI:Saa2)\n",
      "Deleted BEL sentence: p(MGI:Il22) -| bp(GOBP:\"inflammatory response\")\n",
      "Deleted BEL sentence: p(MGI:Il22) -> path(MESHD:Hyperplasia)\n",
      "Deleted BEL sentence: p(MGI:Il22) -> p(MGI:Defb1)\n",
      "Deleted BEL sentence: p(MGI:Il22) -> p(HGNC:IL1B)\n",
      "Deleted BEL sentence: p(MGI:Il22) -> p(HGNC:S100A8)\n",
      "Deleted BEL sentence: p(MGI:Il22) -> p(HGNC:S100A9)\n",
      "Deleted BEL sentence: p(HGNC:IL33) -> p(MGI:Chil3)\n",
      "Deleted BEL sentence: p(MGI:Il3) -> bp(GOBP:\"cell growth\")\n",
      "Deleted BEL sentence: p(MGI:Il3) -| bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: p(MGI:Il3) -| bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: p(MGI:Il3) -| bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: p(MGI:Il3) -> act(p(HGNC:MAPK1))\n",
      "Deleted BEL sentence: p(MGI:Il3) -> act(p(HGNC:MAPK3))\n",
      "Deleted BEL sentence: p(MGI:Il3) -> p(HGNC:MYC)\n",
      "Deleted BEL sentence: p(MGI:Il3) -| p(HGNC:AATK)\n",
      "Deleted BEL sentence: p(MGI:Il3) -> p(HGNC:BIRC5)\n",
      "Deleted BEL sentence: p(MGI:Il3) -| p(HGNC:LCN2)\n",
      "Deleted BEL sentence: p(MGI:Il3) -> p(HGNC:PIM1)\n",
      "Deleted BEL sentence: p(MGI:Il3) -| p(HGNC:ZNF346)\n",
      "Deleted BEL sentence: p(HGNC:IL4R) -> p(MGI:Clca3)\n",
      "Deleted BEL sentence: p(HGNC:IL4) -> p(EGID:20755)\n",
      "Deleted BEL sentence: p(HGNC:IL4) -> p(MGI:Clca3)\n",
      "Deleted BEL sentence: p(HGNC:IL4) -> p(MGI:Sprr2b)\n",
      "Deleted BEL sentence: p(HGNC:IL6) -> p(MGI:Kng1)\n",
      "Deleted BEL sentence: p(HGNC:IL6) -> p(MGI:Serpina3k)\n",
      "Deleted BEL sentence: p(HGNC:IL9) -> p(MGI:Clca3)\n",
      "Deleted BEL sentence: p(HGNC:ING1) -| p(MGI:Ccnb1)\n",
      "Deleted BEL sentence: p(HGNC:IRF4) -| p(EGID:14980)\n",
      "Deleted BEL sentence: p(HGNC:IRF7) -> p(MGI:Ifna1)\n",
      "Deleted BEL sentence: p(HGNC:IRF8) -| p(EGID:14980)\n",
      "Deleted BEL sentence: p(HGNC:IRF8) -| p(MGI:Pmaip1)\n",
      "Deleted BEL sentence: p(HGNC:IRF9) -> p(MGI:Ifna1)\n",
      "Deleted BEL sentence: p(MGI:Irs3) -| bp(GOBP:mitosis)\n",
      "Deleted BEL sentence: p(MGI:Irs3) -> bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: p(MGI:Irs3) -> p(HGNC:EGR1)\n",
      "Deleted BEL sentence: p(MGI:Irs3) -| p(HGNC:IRS2)\n",
      "Deleted BEL sentence: p(MGI:Irs4) -| p(HGNC:IRS2)\n",
      "Deleted BEL sentence: p(HGNC:ITGAV) -> p(MGI:Mcpt1)\n",
      "Deleted BEL sentence: p(HGNC:ITGAV) -> tloc(p(MGI:Mcpt1))\n",
      "Deleted BEL sentence: p(HGNC:JDP2) -> p(MGI:Acp5)\n",
      "Deleted BEL sentence: p(HGNC:JUN) -| act(p(MGI:Casp12))\n",
      "Deleted BEL sentence: p(HGNC:JUN) -| act(p(MGI:Casp12))\n",
      "Deleted BEL sentence: p(HGNC:KEAP1) -| p(EGID:110309)\n",
      "Deleted BEL sentence: p(HGNC:KHDRBS1) -| p(EGID:12096)\n",
      "Deleted BEL sentence: p(HGNC:KHDRBS1) -| p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(MGI:Klk1b4) -> p(HGNC:CHN1)\n",
      "Deleted BEL sentence: p(MGI:Klk1b4) -> p(HGNC:CHN2)\n",
      "Deleted BEL sentence: p(MGI:Ly6a) -| bp(GOBP:\"T cell proliferation\")\n",
      "Deleted BEL sentence: p(MGI:Ly6a) -> tloc(p(HGNC:IL4))\n",
      "Deleted BEL sentence: p(HGNC:MAB21L1) -> p(MGI:Foxe3)\n",
      "Deleted BEL sentence: p(HGNC:MAP2K7) -> act(complex(p(EGID:12534),p(MGI:Ccnb1)))\n",
      "Deleted BEL sentence: p(HGNC:MAP2K7) -> p(EGID:12534)\n",
      "Deleted BEL sentence: p(MGI:Map3k7) -> p(HGNC:LOX)\n",
      "Deleted BEL sentence: p(MGI:Map3k7) -> p(HGNC:THBS1)\n",
      "Deleted BEL sentence: p(MGI:Map3k7) -> p(HGNC:TIMP3)\n",
      "Deleted BEL sentence: p(MGI:Map3k7) -> p(HGNC:VCL)\n",
      "Deleted BEL sentence: p(HGNC:MMP12) -| p(MGI:Serpina1a)\n",
      "Deleted BEL sentence: p(HGNC:MMP12) -| p(MGI:Serpina1b)\n",
      "Deleted BEL sentence: p(HGNC:MMP7) -> deg(p(MGI:Eln))\n",
      "Deleted BEL sentence: p(MGI:Mt1) -| bp(GOBP:\"response to oxidative stress\")\n",
      "Deleted BEL sentence: p(MGI:Mt1) -> p(MGI:Serpina3k)\n",
      "Deleted BEL sentence: p(MGI:Mt1) -| p(HGNC:TKT)\n",
      "Deleted BEL sentence: p(MGI:Mt1) -| p(MGI:Vnn3)\n",
      "Deleted BEL sentence: p(MGI:Muc4) -> bp(GOBP:\"cell growth\")\n",
      "Deleted BEL sentence: p(MGI:Muc4) -> act(p(HGNC:MAPK1))\n",
      "Deleted BEL sentence: p(MGI:Muc4) -> act(p(HGNC:MAPK3))\n",
      "Deleted BEL sentence: p(MGI:Muc4) -> p(HGNC:ERBB2)\n",
      "Deleted BEL sentence: p(MGI:Muc4) -> p(HGNC:ERBB2,pmod(P))\n",
      "Deleted BEL sentence: p(HGNC:NCOR2) -| p(EGID:216850)\n",
      "Deleted BEL sentence: p(HGNC:NFE2) -> p(MGI:Hsd3b6)\n",
      "Deleted BEL sentence: p(HGNC:NGEF) -| act(p(MGI:Cdc42))\n",
      "Deleted BEL sentence: p(HGNC:NIF3L1) -> act(p(MGI:Cops2))\n",
      "Deleted BEL sentence: p(MGI:\"Nkx2-1\") -> bp(GOBP:\"inflammatory response\")\n",
      "Deleted BEL sentence: p(MGI:\"Nkx2-1\") -> path(MESHD:Emphysema)\n",
      "Deleted BEL sentence: p(MGI:\"Nkx2-5\") -> act(p(HGNC:GATA4))\n",
      "Deleted BEL sentence: p(HGNC:NOS2) -> p(EGID:20755)\n",
      "Deleted BEL sentence: p(HGNC:NOS3) -| p(MGI:Madcam1)\n",
      "Deleted BEL sentence: p(HGNC:NOS3) -| p(MGI:Cyp2c29)\n",
      "Deleted BEL sentence: p(MGI:Nrg1) -> p(HGNC:ERRFI1)\n",
      "Deleted BEL sentence: p(HGNC:ORMDL3) -> p(MGI:Cxcl11)\n",
      "Deleted BEL sentence: p(HGNC:PAX9) -| p(MGI:Krt10)\n",
      "Deleted BEL sentence: p(HGNC:PAX9) -| p(MGI:Krt2)\n",
      "Deleted BEL sentence: p(MGI:Pde4d) -> bp(GOBP:\"neutrophil chemotaxis\")\n",
      "Deleted BEL sentence: p(MGI:Pde4d) -> p(HGNC:TNF)\n",
      "Deleted BEL sentence: p(HGNC:PDE7A) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: p(HGNC:PDPK1) -| complex(p(HGNC:PDPK1),p(MGI:Ywhaq))\n",
      "Deleted BEL sentence: p(HGNC:PDPK1) -| complex(p(HGNC:PDPK1),p(MGI:Ywhaq))\n",
      "Deleted BEL sentence: p(HGNC:PDPK1) -> complex(p(HGNC:PDPK1),p(MGI:Ywhaq))\n",
      "Deleted BEL sentence: p(HGNC:PHOX2B) -| p(MGI:\"Nkx6-1\")\n",
      "Deleted BEL sentence: p(HGNC:PHOX2B) -| p(MGI:\"Nkx6-2\")\n",
      "Deleted BEL sentence: p(HGNC:PLA2G6) -> act(p(MGI:Ighm))\n",
      "Deleted BEL sentence: p(HGNC:PLAA) -> p(MGI:\"mt-Co2\")\n",
      "Deleted BEL sentence: p(MGI:Pln) -| p(HGNC:FKBP1A)\n",
      "Deleted BEL sentence: p(MGI:Pln) -| p(HGNC:RYR1)\n",
      "Deleted BEL sentence: p(MGI:Pmaip1) -> act(p(HGNC:BAK1))\n",
      "Deleted BEL sentence: p(MGI:Pmaip1) -> act(p(HGNC:CASP7))\n",
      "Deleted BEL sentence: p(HGNC:POR) -| p(MGI:Cyp2c29)\n",
      "Deleted BEL sentence: p(HGNC:POR) -| p(MGI:Cyp3a11)\n",
      "Deleted BEL sentence: p(HGNC:POR) -| p(MGI:Scd2)\n",
      "Deleted BEL sentence: p(HGNC:PPP1R15A) -> act(p(MGI:Ppp1cc))\n",
      "Deleted BEL sentence: p(HGNC:PPP1R15A) -> p(MGI:Ppp1cc)\n",
      "Deleted BEL sentence: p(HGNC:PRDM16) -| p(MGI:Serpina3k)\n",
      "Deleted BEL sentence: p(MGI:Retnla) -> bp(GOBP:angiogenesis)\n",
      "Deleted BEL sentence: p(MGI:Retnla) -> bp(GOBP:\"cell proliferation\")\n",
      "Deleted BEL sentence: p(HGNC:RNF2) -| p(MGI:Pmaip1)\n",
      "Deleted BEL sentence: p(HGNC:RXRG) -> p(MGI:Cyp2c29)\n",
      "Deleted BEL sentence: p(MGI:Sepp1) -> bp(GOBP:\"cell growth\")\n",
      "Deleted BEL sentence: p(MGI:Sepp1) -| path(MESHD:Ataxia)\n",
      "Deleted BEL sentence: p(MGI:Serpina1b) -| act(p(HGNC:PLG))\n",
      "Deleted BEL sentence: p(HGNC:SERPINE1) -| p(MGI:Klrb1c)\n",
      "Deleted BEL sentence: p(MGI:Sik1,pmod(P)) -> tloc(p(MGI:Sik1))\n",
      "Deleted BEL sentence: p(MGI:Sik1) -| act(p(HGNC:CREB1))\n",
      "Deleted BEL sentence: p(HGNC:SOCS2) -| p(MGI:Ifna1)\n",
      "Deleted BEL sentence: p(HGNC:SOCS2) -> p(MGI:Mup1)\n",
      "Deleted BEL sentence: p(HGNC:SOCS3) -| p(MGI:Ifna1)\n",
      "Deleted BEL sentence: p(HGNC:SOD2) -> p(MGI:Hspa1a)\n",
      "Deleted BEL sentence: p(HGNC:SOD2) -| p(MGI:Mt1)\n",
      "Deleted BEL sentence: p(HGNC:SOD2) -| p(MGI:Mt2)\n",
      "Deleted BEL sentence: p(HGNC:SOX15) -| p(MGI:Hrc)\n",
      "Deleted BEL sentence: p(HGNC:SPP1) -> p(EGID:12096)\n",
      "Deleted BEL sentence: p(HGNC:SPP1) -| p(MGI:\"mt-Co1\")\n",
      "Deleted BEL sentence: p(HGNC:TAF4B) -> p(MGI:Bmp8b)\n",
      "Deleted BEL sentence: p(HGNC:TBX21) -> p(MGI:Ighg2b)\n",
      "Deleted BEL sentence: p(HGNC:TBX21) -| p(EGID:16020)\n",
      "Deleted BEL sentence: p(HGNC:TBX21) -> p(EGID:380793)\n",
      "Deleted BEL sentence: p(HGNC:TBX21) -| p(MGI:Ighg1)\n",
      "Deleted BEL sentence: p(HGNC:TBX21) -> p(EGID:380793)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387222)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387222)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387223)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387223)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387224)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:387224)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -| p(EGID:69717)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mcpt1)\n",
      "Deleted BEL sentence: p(HGNC:TLR2) -| p(EGID:12765)\n",
      "Deleted BEL sentence: p(HGNC:TLR4) -| deg(p(MGI:Eln))\n",
      "Deleted BEL sentence: p(HGNC:TLR7) -> p(MGI:Ifna2)\n",
      "Deleted BEL sentence: p(HGNC:TNF) -| p(EGID:387223)\n",
      "Deleted BEL sentence: p(HGNC:TNF) -> p(MGI:Ccl6)\n",
      "Deleted BEL sentence: p(HGNC:TWSG1) -| act(p(EGID:109899))\n",
      "Deleted BEL sentence: p(HGNC:TWSG1) -| p(MGI:Bglap2)\n",
      "Deleted BEL sentence: p(HGNC:TYROBP) -| p(MGI:Icosl)\n",
      "Deleted BEL sentence: p(HGNC:WNT3A) -> p(EGID:12096)\n",
      "Deleted BEL sentence: p(HGNC:XBP1) -> p(EGID:13216)\n",
      "Deleted BEL sentence: p(HGNC:XBP1) -> p(EGID:13238)\n",
      "Deleted BEL sentence: p(HGNC:XBP1) -> p(EGID:13239)\n",
      "Deleted BEL sentence: p(HGNC:XBP1) -> p(MGI:Lyz2)\n",
      "Deleted BEL sentence: p(HGNC:ZFPM1) -> p(MGI:\"Hba-a1\")\n",
      "Deleted BEL sentence: p(HGNC:ZFPM1) -> p(MGI:\"Hbb-b1\")\n",
      "Deleted BEL sentence: p(HGNC:ZFPM1) -> p(MGI:Srgn)\n",
      "Deleted BEL sentence: p(EGID:387243) -| p(HGNC:NFAT5)\n",
      "Deleted BEL sentence: p(EGID:387243) -| act(p(HGNC:NFAT5))\n",
      "Deleted BEL sentence: p(EGID:751531) -| p(HGNC:NFAT5)\n",
      "Deleted BEL sentence: p(EGID:751531) -| act(p(HGNC:NFAT5))\n",
      "Deleted BEL sentence: p(MGI:Mir155) -| p(HGNC:IL10)\n",
      "Deleted BEL sentence: p(MGI:Mir155) -| p(HGNC:IL4)\n",
      "Deleted BEL sentence: p(MGI:Mir155) -| p(HGNC:IL5)\n",
      "Deleted BEL sentence: act(p(HGNC:AHR)) -> p(MGI:Il22)\n",
      "Deleted BEL sentence: act(p(HGNC:AR)) -> p(MGI:Pbsn)\n",
      "Deleted BEL sentence: act(p(MGI:Atf1)) -| bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: act(p(HGNC:ATF4)) -> p(MGI:Bglap2)\n",
      "Deleted BEL sentence: act(p(HGNC:BCL6)) -| p(MGI:Ccl6)\n",
      "Deleted BEL sentence: act(p(HGNC:BCL6)) -| p(MGI:Ccl7)\n",
      "Deleted BEL sentence: act(p(MGI:Bhlhe41)) -| p(HGNC:CEBPA)\n",
      "Deleted BEL sentence: act(p(MGI:Bhlhe41)) -| p(HGNC:PPARG)\n",
      "Deleted BEL sentence: act(p(HGNC:CEBPB)) -| p(MGI:Dspp)\n",
      "Deleted BEL sentence: act(p(HGNC:CREB1)) -> p(MGI:\"H2-Eb2\")\n",
      "Deleted BEL sentence: act(p(HGNC:CREB1)) -> p(MGI:Pvrl2)\n",
      "Deleted BEL sentence: act(p(MGI:Cux1)) -| p(HGNC:RUNX2)\n",
      "Deleted BEL sentence: act(p(HGNC:E2F1)) -> p(MGI:Hrk)\n",
      "Deleted BEL sentence: act(p(HGNC:E2F1)) -> p(MGI:Pmaip1)\n",
      "Deleted BEL sentence: act(p(HGNC:E2F4)) -> p(MGI:Ccnb1)\n",
      "Deleted BEL sentence: act(p(MGI:Eno1)) -> bp(GOBP:\"cell death\")\n",
      "Deleted BEL sentence: act(p(MGI:Eno1)) -| p(HGNC:MYC)\n",
      "Deleted BEL sentence: act(p(MGI:Eno1)) -| p(HGNC:MYC)\n",
      "Deleted BEL sentence: act(p(HGNC:EOMES)) -> p(MGI:Gzmb)\n",
      "Deleted BEL sentence: act(p(HGNC:EPAS1)) -> p(MGI:Irs3)\n",
      "Deleted BEL sentence: act(p(HGNC:ESR1)) -| p(EGID:100124672)\n",
      "Deleted BEL sentence: act(p(MGI:Esrra)) -> bp(GOBP:\"fatty acid oxidation\")\n",
      "Deleted BEL sentence: act(p(HGNC:FLI1)) -| p(EGID:15127)\n",
      "Deleted BEL sentence: act(p(HGNC:FOS)) -> p(MGI:Pvrl2)\n",
      "Deleted BEL sentence: act(p(HGNC:FOXA2)) -> p(MGI:Gcg)\n",
      "Deleted BEL sentence: act(p(HGNC:FOXO1)) -> p(MGI:Apoc3)\n",
      "Deleted BEL sentence: act(p(MGI:Foxp2)) -| p(HGNC:SCGB1A1)\n",
      "Deleted BEL sentence: act(p(MGI:Foxp2)) -| p(HGNC:SFTPC)\n",
      "Deleted BEL sentence: act(p(HGNC:GABPB2)) -> p(MGI:\"mt-Co2\")\n",
      "Deleted BEL sentence: act(p(HGNC:GTF2IRD1)) -> p(EGID:111507)\n",
      "Deleted BEL sentence: act(p(HGNC:GTF2IRD1)) -| p(EGID:111507)\n",
      "Deleted BEL sentence: act(p(HGNC:HIF1A)) -> p(EGID:387206)\n",
      "Deleted BEL sentence: act(p(HGNC:HOXC13)) -> p(MGI:Stfa3)\n",
      "Deleted BEL sentence: act(p(HGNC:IRF1)) -> p(MGI:Ifi47)\n",
      "Deleted BEL sentence: act(p(HGNC:JDP2)) -| p(MGI:Fus)\n",
      "Deleted BEL sentence: act(p(HGNC:JUN)) -> p(EGID:12534)\n",
      "Deleted BEL sentence: act(p(HGNC:JUN)) -> p(MGI:Pvrl2)\n",
      "Deleted BEL sentence: act(p(HGNC:KLF5)) -> act(p(EGID:12534))\n",
      "Deleted BEL sentence: act(p(HGNC:KLF5)) -> p(EGID:12534)\n",
      "Deleted BEL sentence: act(p(HGNC:KLF5)) -> p(MGI:Ccnb1)\n",
      "Deleted BEL sentence: act(p(HGNC:LHX9)) -> p(MGI:Sf1)\n",
      "Deleted BEL sentence: act(p(HGNC:LMX1A)) -> p(MGI:Ins1)\n",
      "Deleted BEL sentence: act(p(HGNC:MAFG)) -> p(MGI:\"Hba-a1\")\n",
      "Deleted BEL sentence: act(p(HGNC:MAFG)) -> p(MGI:\"Hbb-b1\")\n",
      "Deleted BEL sentence: act(p(HGNC:MAZ)) -> p(MGI:Ins1)\n",
      "Deleted BEL sentence: act(p(HGNC:MITF)) -> p(MGI:Tpsab1)\n",
      "Deleted BEL sentence: act(p(MGI:Msx3)) -| p(HGNC:MSX1)\n",
      "Deleted BEL sentence: act(p(HGNC:MTF1)) -> p(MGI:Mt1)\n",
      "Deleted BEL sentence: act(p(HGNC:MTF1)) -> p(MGI:Mt1)\n",
      "Deleted BEL sentence: act(p(HGNC:MYC)) -> p(EGID:19368)\n",
      "Deleted BEL sentence: act(p(HGNC:NFE2L1)) -| p(MGI:Cyp4a10)\n",
      "Deleted BEL sentence: act(p(HGNC:NFE2L1)) -| p(MGI:Cyp4a14)\n",
      "Deleted BEL sentence: act(p(HGNC:NFE2L1)) -| p(MGI:Dspp)\n",
      "Deleted BEL sentence: act(p(HGNC:NFE2L2)) -> p(EGID:110309)\n",
      "Deleted BEL sentence: act(p(HGNC:NFIA)) -> act(p(MGI:\"Nkx2-1\"))\n",
      "Deleted BEL sentence: act(p(HGNC:NFIB)) -> act(p(MGI:\"Nkx2-1\"))\n",
      "Deleted BEL sentence: act(p(MGI:\"Nkx2-1\")) -> p(HGNC:SFTPD)\n",
      "Deleted BEL sentence: act(p(MGI:\"Nkx2-5\")) -> p(HGNC:ADORA1)\n",
      "Deleted BEL sentence: act(p(MGI:\"Nkx2-5\")) -> p(HGNC:PITX2)\n",
      "Deleted BEL sentence: act(p(MGI:\"Nkx2-5\")) -> p(HGNC:XIRP1)\n",
      "Deleted BEL sentence: act(p(HGNC:NR1I3)) -| p(MGI:Slco1a1)\n",
      "Deleted BEL sentence: act(p(HGNC:NR1I3)) -> p(MGI:Sult2a1)\n",
      "Deleted BEL sentence: act(p(HGNC:NR4A2)) -> p(MGI:Cdkn1c)\n",
      "Deleted BEL sentence: act(p(HGNC:PAX6)) -| p(MGI:\"Nkx2-1\")\n",
      "Deleted BEL sentence: act(p(HGNC:POU3F4)) -> p(MGI:Gcg)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARA)) -| p(EGID:20493)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARA)) -| p(MGI:Apoc3)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARA)) -| p(MGI:Eif1)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARA)) -| p(MGI:Slco1a1)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARA)) -| p(MGI:Slco1a4)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARD)) -> p(EGID:11520)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARG)) -> p(MGI:Flg)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARG)) -> p(MGI:Ivl)\n",
      "Deleted BEL sentence: act(p(HGNC:PPARG)) -> p(MGI:Lor)\n",
      "Deleted BEL sentence: act(p(HGNC:RB1)) -> p(EGID:12096)\n",
      "Deleted BEL sentence: act(p(HGNC:RB1)) -> p(MGI:Bglap2)\n",
      "Deleted BEL sentence: act(p(HGNC:RB1)) -> tloc(p(EGID:12096))\n",
      "Deleted BEL sentence: act(p(HGNC:RB1)) -> tloc(p(MGI:Bglap2))\n",
      "Deleted BEL sentence: act(p(HGNC:RELB)) -> p(MGI:Ccl19)\n",
      "Deleted BEL sentence: act(p(HGNC:RELB)) -> p(MGI:Ccl21a)\n",
      "Deleted BEL sentence: act(p(HGNC:RUNX2)) -> p(MGI:Bglap2)\n",
      "Deleted BEL sentence: act(p(HGNC:SATB2)) -> p(MGI:Ighm)\n",
      "Deleted BEL sentence: act(p(HGNC:SMAD1)) -> p(MGI:\"Nkx2-5\")\n",
      "Deleted BEL sentence: act(p(HGNC:SMAD4)) -> p(MGI:\"Nkx2-5\")\n",
      "Deleted BEL sentence: act(p(HGNC:SMARCA2)) -> p(MGI:Pbsn)\n",
      "Deleted BEL sentence: act(p(HGNC:SMARCA4)) -> p(MGI:Pbsn)\n",
      "Deleted BEL sentence: act(p(HGNC:SPI1)) -| p(MGI:\"Hbb-b2\")\n",
      "Deleted BEL sentence: act(p(HGNC:STAT4)) -> p(MGI:Ccl6)\n",
      "Deleted BEL sentence: act(p(HGNC:TBX21)) -> act(p(MGI:Gzmb))\n",
      "Deleted BEL sentence: act(p(MGI:Tcf7)) -> p(HGNC:RUNX2)\n",
      "Deleted BEL sentence: act(p(HGNC:TP53)) -> p(MGI:Pmaip1)\n",
      "Deleted BEL sentence: act(p(HGNC:TP53)) -> p(MGI:Pmaip1)\n",
      "Deleted BEL sentence: act(p(MGI:Ttf1)) -> p(HGNC:SFTPD)\n",
      "Deleted BEL sentence: act(p(HGNC:USF1)) -> p(MGI:Mt1)\n",
      "Deleted BEL sentence: act(p(HGNC:USF1)) -> p(MGI:Mt1)\n",
      "Deleted BEL sentence: act(p(HGNC:USF1)) -> p(MGI:Prnd)\n",
      "Deleted BEL sentence: act(p(HGNC:WT1)) -> p(MGI:Sf1)\n",
      "Deleted BEL sentence: act(p(HGNC:YBX3)) -| p(MGI:Prm1)\n",
      "Deleted BEL sentence: act(p(HGNC:YBX3)) -| p(MGI:Prm2)\n",
      "Deleted BEL sentence: act(p(MGI:Tlr9 )) -| bp(GOBP:\"regulatory T cell differentiation\")\n",
      "Deleted BEL sentence: act(p(MGI:Tlr9 )) -> bp(GOBP:\"apoptotic process\")\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Tnfsf9)\n",
      "Deleted BEL sentence: act(p(HGNC:TLR9)) -> p(MGI:Tnfsf9)\n",
      "Deleted BEL sentence: act(p(MGI:Klrk1)) -> tloc(p(HGNC:IFNG))\n",
      "Deleted BEL sentence: p(HGNC:S100A9) -> p(MGI:Nfkb1, pmod(P,S,536))\n",
      "Deleted BEL sentence: p(HGNC:S100A8) -> p(MGI:Nfkb1, pmod(P,S,536))\n",
      "Deleted BEL sentence: p(HGNC:IL6) -| p(MGI:Il1r1 )\n",
      "Deleted BEL sentence: p(HGNC:CSF3) -> p(MGI:Il1r1 )\n",
      "Deleted BEL sentence: p(HGNC:CSF2) -> p(MGI:Il1r1 )\n",
      "Deleted BEL sentence: act(p(MGI:Hif1a )) -| a(CHEBI:\"reactive oxygen species\")\n",
      "Deleted BEL sentence: act(p(HGNC:HIF1A)) -> p(MGI:Emr1)\n",
      "Deleted BEL sentence: p(HGNC:IL1B) -| p(MGI:Ly6c1)\n",
      "Deleted BEL sentence: p(HGNC:IL1B) -| p(MGI:Klrk1)\n",
      "Deleted BEL sentence: p(HGNC:IL1B) -| p(MGI:Klrk1)\n",
      "Deleted BEL sentence: path(MESHD:\"Breast Neoplasms\") -| p(MGI:Klrk1)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir223)\n",
      "Deleted BEL sentence: p(HGNC:PTGS2) -| p(MGI:Mir223)\n",
      "Deleted BEL sentence: p(MGI:Mir223) -| p(HGNC:MEF2C)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir20a)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir17)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir17)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir20a)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| p(HGNC:CYBB)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| p(HGNC:NCF1)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| p(HGNC:CYBB)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| p(HGNC:NCF1)\n",
      "Deleted BEL sentence: complex(p(MGI:Mir20a),act(p(HGNC:STAT3))) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: complex(p(MGI:Mir17),act(p(HGNC:STAT3))) -| p(HGNC:STAT3)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| a(CHEBI:\"reactive oxygen species\")\n",
      "Deleted BEL sentence: p(MGI:Mir17) -| a(CHEBI:dioxidaniumyl)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| a(CHEBI:dioxidaniumyl)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -| a(CHEBI:\"reactive oxygen species\")\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir17)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir20a)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir17)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| p(MGI:Mir20a)\n",
      "Deleted BEL sentence: p(MGI:Mir17) -> a(CHEBI:\"reactive oxygen species\")\n",
      "Deleted BEL sentence: p(MGI:Mir17) -> a(CHEBI:dioxidaniumyl)\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -> a(CHEBI:\"reactive oxygen species\")\n",
      "Deleted BEL sentence: p(MGI:Mir20a) -> a(CHEBI:dioxidaniumyl)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -> p(HGNC:MMP14)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -> p(HGNC:MMP13)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -> p(HGNC:TINAGL1)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -> p(HGNC:MMP2)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -| act(p(HGNC:ARG1))\n",
      "Deleted BEL sentence: p(MGI:Mir494) -| p(HGNC:PTEN)\n",
      "Deleted BEL sentence: p(HGNC:TGFB1) -> p(MGI:Mir494)\n",
      "Deleted BEL sentence: p(MGI:Mir494) -| p(HGNC:PTEN)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -| complex(p(MGI:Csl),p(HGNC:RBPJ))\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir21)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir155)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir155)\n",
      "Deleted BEL sentence: bp(GOBP:\"response to tumor cell\") -> p(MGI:Mir21)\n",
      "Deleted BEL sentence: p(MGI:Cyp2a4) -| act(p(HGNC:STAT3))\n",
      "Deleted BEL sentence: p(MGI:Cyp2a4) -| act(p(HGNC:STAT3))\n",
      "Deleted BEL sentence: complex(p(MGI:Itgav ),p(HGNC:ITGB1)) -> path(MESHD:\"Neovascularization, Pathologic\")\n",
      "Deleted BEL sentence: complex(p(MGI:Itgav ),p(HGNC:ITGB1)) -> bp(GOBP:\"cell adhesion\")\n",
      "Deleted BEL sentence: complex(p(MGI:Itgav ),p(HGNC:ITGB1)) -> bp(GOBP:\"macrophage chemotaxis\")\n",
      "Deleted BEL sentence: complex(p(MGI:Itgav ),p(HGNC:ITGB1)) -> bp(GOBP:\"blood vessel development\")\n",
      "Deleted BEL sentence: p(MGI:Mir190) -| p(HGNC:TIMP3)\n",
      "Deleted BEL sentence: p(MGI:Mir190) -| p(HGNC:TGFA)\n",
      "Deleted BEL sentence: p(MGI:Mir190) -> p(HGNC:AMOT)\n",
      "Deleted BEL sentence: p(MGI:Mir190) -> p(HGNC:EPHA5)\n",
      "Deleted BEL sentence: p(MGI:Mir190) -| p(HGNC:TGFA)\n",
      "Word in BEL converted to unknown: GOBP:mitosis\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:MRE11A\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: CHEBI:octreotide\n",
      "Word in BEL converted to unknown: CHEBI:octreotide\n",
      "Word in BEL converted to unknown: CHEBI:octreotide\n",
      "Word in BEL converted to unknown: CHEBI:\"palmitic acid\"\n",
      "Word in BEL converted to unknown: GOBP:mitosis\n",
      "Word in BEL converted to unknown: GOBP:mitosis\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: CHEBI:\"cholesterol ester\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: CHEBI:\"palmitoleic acid\"\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:PARK2\n",
      "Word in BEL converted to unknown: HGNC:PARK2\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: CHEBI:\"lactic acid\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:ERBB2IP\n",
      "Word in BEL converted to unknown: HGNC:ERBB2IP\n",
      "Word in BEL converted to unknown: HGNC:FIGF\n",
      "Word in BEL converted to unknown: HGNC:FIGF\n",
      "Word in BEL converted to unknown: HGNC:FIGF\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:ATP5E\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:mitosis\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: GOBP:mitosis\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: GOBP:\"Wnt receptor signaling pathway\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:MRE11A\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:glycolysis\n",
      "Word in BEL converted to unknown: HGNC:ERO1L\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:MRE11A\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: GOBP:\"patterning of blood vessels\"\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "Word in BEL converted to unknown: HGNC:IL8\n",
      "[9, 2, 5, 2, 545, 3, 3, 14, 5, 2, 40688, 3] [5092, 12123, 1267, 8069, 1494, 6667, 14919, 664, 18197, 6163, 16515, 14174, 12249, 4008, 4954, 17623, 4954, 11195, 4954, 908, 8165, 908, 7016, 16914, 7505, 14521, 3110, 4954, 7212, 18072, 11758, 908, 13527, 3653, 9902, 4954, 5591, 4665, 15759, 18367, 11825, 10358]\n"
     ]
    }
   ],
   "source": [
    "sentences = loadSentences('dataset/TrainingNormalised.BEL')\n",
    "trainBSentences = []\n",
    "trainBTokenized = []\n",
    "trainTSentences = []\n",
    "trainTTokenized = []\n",
    "for line in sentences:\n",
    "    BELTokens = tokeniseBEL(line['BEL-normalised'], mapToHGNC = True)\n",
    "    if not BELTokens:\n",
    "        print('Deleted BEL sentence:', line['BEL-normalised'])\n",
    "        continue\n",
    "    trainBSentences.append(line['BEL-normalised'])\n",
    "    trainBTokenized.append(BELTokens)\n",
    "    trainTSentences.append(TextSentenceID[line['Sentence-ID'][4:]]['text'])\n",
    "    trainTTokenized.append(TextSentenceID[line['Sentence-ID'][4:]]['tokens'])\n",
    "trainT = [words2index(sublist, T_w2idx) for sublist in trainTTokenized]\n",
    "trainB = [words2index(sublist, B_w2idx) for sublist in trainBTokenized]\n",
    "print(trainB[150], trainT[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(encode_seqs, decode_seqs, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for translation, you need 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = T_vocab_size_total,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'encode_seq_embedding')\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = B_vocab_size_total,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'decode_seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "            tl.layers.set_name_reuse(True)\n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 1,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "        net_out = DenseLayer(net_rnn, n_units=B_vocab_size_total, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn, net_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelWithAttention(encode_seqs, decode_seqs, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for translation, you need 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = T_vocab_size_total,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'encode_seq_embedding')\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = B_vocab_size_total,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'decode_seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "            tl.layers.set_name_reuse(True)\n",
    "#         net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "#                 cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "#                 n_hidden = emb_dim,\n",
    "#                 initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "#                 encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "#                 decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "#                 initial_state_encode = None,\n",
    "#                 dropout = (0.5 if is_train else None),\n",
    "#                 n_layer = 1,\n",
    "#                 return_seq_2d = True,\n",
    "#                 name = 'seq2seq')\n",
    "#         with tf.variable_scope('seq2seq'):\n",
    "#             tl.layers.set_name_reuse(True)\n",
    "            # network = InputLayer(self.inputs, name=name+'/input')\n",
    "        network_encode = DynamicRNNLayer(\n",
    "            net_encode,\n",
    "            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n",
    "            n_hidden=emb_dim,\n",
    "            initializer=tf.random_uniform_initializer(-0.1, 0.1),\n",
    "            initial_state=None,\n",
    "            dropout=(0.5 if is_train else None),\n",
    "            n_layer=1,\n",
    "            sequence_length=retrieve_seq_length_op2(encode_seqs),\n",
    "            return_last=False,\n",
    "            return_seq_2d=False,\n",
    "            name='seq2seq_encode')\n",
    "#             attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "#                 num_units = emb_dim,\n",
    "#                 memory = network_encode.outputs,\n",
    "#                 memory_sequence_length = None # Might be made more accurate later \n",
    "#                 )\n",
    "#             cell = tf.contrib.rnn.BasicLSTMCell(num_units = emb_dim)\n",
    "#             attn_cell = tf.contrib.seq2seq.AttentionWrapper(cell, attention_mechanism)\n",
    "#             network_decode = DynamicRNNLayer(\n",
    "#                 net_decode,\n",
    "#                 cell_fn=attn_cell,\n",
    "#                 n_hidden=emb_dim,\n",
    "#                 initializer=tf.random_uniform_initializer(-0.1, 0.1),\n",
    "#                 initial_state=(network_encode.final_state if initial_state_decode is None else initial_state_decode),\n",
    "#                 dropout=(0.5 if is_train else None),\n",
    "#                 n_layer=1,\n",
    "#                 sequence_length=retrieve_seq_length_op2(decode_seqs),\n",
    "#                 return_last=False,\n",
    "#                 return_seq_2d=True,\n",
    "#                 name='seq2seq_decode')\n",
    "        network_decode = DynamicRNNLayerWithAttention(\n",
    "            net_decode,\n",
    "            cell_fn=tf.contrib.rnn.BasicLSTMCell,\n",
    "            attention_mechanism_fn=tf.contrib.seq2seq.BahdanauAttention,\n",
    "            memory=network_encode.outputs,\n",
    "            n_hidden=emb_dim,\n",
    "            initializer=tf.random_uniform_initializer(-0.1, 0.1),\n",
    "            initial_state=network_encode.final_state,\n",
    "           # initial_state=(network_encode.final_state if is_train else None),\n",
    "            dropout=(0.5 if is_train else None),\n",
    "            n_layer=1,\n",
    "            sequence_length=retrieve_seq_length_op2(decode_seqs),\n",
    "            return_last=False,\n",
    "            return_seq_2d=True,\n",
    "            name='seq2seq_decode')\n",
    "        net_out = DenseLayer(network_decode, n_units=B_vocab_size_total, act=tf.identity, name='output')\n",
    "    return net_out, network_encode, net_encode, network_decode, network_decode.cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicRNNLayerWithAttention(Layer):\n",
    "    \"\"\"\n",
    "    The :class:`DynamicRNNLayer` class is a dynamic recurrent layer, see ``tf.nn.dynamic_rnn``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    layer : :class:`Layer`\n",
    "        Previous layer\n",
    "    cell_fn : TensorFlow cell function\n",
    "        A TensorFlow core RNN cell\n",
    "            - See `RNN Cells in TensorFlow <https://www.tensorflow.org/api_docs/python/>`__\n",
    "            - Note TF1.0+ and TF1.0- are different\n",
    "    cell_init_args : dictionary or None\n",
    "        The arguments for the cell function.\n",
    "    n_hidden : int\n",
    "        The number of hidden units in the layer.\n",
    "    initializer : initializer\n",
    "        The initializer for initializing the parameters.\n",
    "    sequence_length : tensor, array or None\n",
    "        The sequence length of each row of input data, see ``Advanced Ops for Dynamic RNN``.\n",
    "            - If None, it uses ``retrieve_seq_length_op`` to compute the sequence length, i.e. when the features of padding (on right hand side) are all zeros.\n",
    "            - If using word embedding, you may need to compute the sequence length from the ID array (the integer features before word embedding) by using ``retrieve_seq_length_op2`` or ``retrieve_seq_length_op``.\n",
    "            - You can also input an numpy array.\n",
    "            - More details about TensorFlow dynamic RNN in `Wild-ML Blog <http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/>`__.\n",
    "    initial_state : None or RNN State\n",
    "        If None, `initial_state` is zero state.\n",
    "    dropout : tuple of float or int\n",
    "        The input and output keep probability (input_keep_prob, output_keep_prob).\n",
    "            - If one int, input and output keep probability are the same.\n",
    "    n_layer : int\n",
    "        The number of RNN layers, default is 1.\n",
    "    return_last : boolean or None\n",
    "        Whether return last output or all outputs in each step.\n",
    "            - If True, return the last output, \"Sequence input and single output\"\n",
    "            - If False, return all outputs, \"Synced sequence input and output\"\n",
    "            - In other word, if you want to stack more RNNs on this layer, set to False.\n",
    "    return_seq_2d : boolean\n",
    "        Only consider this argument when `return_last` is `False`\n",
    "            - If True, return 2D Tensor [n_example, n_hidden], for stacking DenseLayer after it.\n",
    "            - If False, return 3D Tensor [n_example/n_steps, n_steps, n_hidden], for stacking multiple RNN after it.\n",
    "    dynamic_rnn_init_args : dictionary\n",
    "        The arguments for ``tf.nn.dynamic_rnn``.\n",
    "    name : str\n",
    "        A unique layer name.\n",
    "\n",
    "    Attributes\n",
    "    ------------\n",
    "    outputs : tensor\n",
    "        The output of this layer.\n",
    "\n",
    "    final_state : tensor or StateTuple\n",
    "        The finial state of this layer.\n",
    "            - When `state_is_tuple` is `False`, it is the final hidden and cell states, `states.get_shape() = [?, 2 * n_hidden]`.\n",
    "            - When `state_is_tuple` is `True`, it stores two elements: `(c, h)`.\n",
    "            - In practice, you can get the final state after each iteration during training, then feed it to the initial state of next iteration.\n",
    "\n",
    "    initial_state : tensor or StateTuple\n",
    "        The initial state of this layer.\n",
    "            - In practice, you can set your state at the begining of each epoch or iteration according to your training procedure.\n",
    "\n",
    "    batch_size : int or tensor\n",
    "        It is an integer, if it is able to compute the `batch_size`; otherwise, tensor for dynamic batch size.\n",
    "\n",
    "    sequence_length : a tensor or array\n",
    "        The sequence lengths computed by Advanced Opt or the given sequence lengths, [batch_size]\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Input dimension should be rank 3 : [batch_size, n_steps(max), n_features], if no, please see :class:`ReshapeLayer`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Synced sequence input and output, for loss function see ``tl.cost.cross_entropy_seq_with_mask``.\n",
    "\n",
    "    >>> input_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"input\")\n",
    "    >>> net = tl.layers.EmbeddingInputlayer(\n",
    "    ...             inputs = input_seqs,\n",
    "    ...             vocabulary_size = vocab_size,\n",
    "    ...             embedding_size = embedding_size,\n",
    "    ...             name = 'seq_embedding')\n",
    "    >>> net = tl.layers.DynamicRNNLayer(net,\n",
    "    ...             cell_fn = tf.contrib.rnn.BasicLSTMCell, # for TF0.2 use tf.nn.rnn_cell.BasicLSTMCell,\n",
    "    ...             n_hidden = embedding_size,\n",
    "    ...             dropout = (0.7 if is_train else None),\n",
    "    ...             sequence_length = tl.layers.retrieve_seq_length_op2(input_seqs),\n",
    "    ...             return_seq_2d = True,                   # stack denselayer or compute cost after it\n",
    "    ...             name = 'dynamicrnn')\n",
    "    ... net = tl.layers.DenseLayer(net, n_units=vocab_size, name=\"output\")\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - `Wild-ML Blog <http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/>`__\n",
    "    - `dynamic_rnn.ipynb <https://github.com/dennybritz/tf-rnn/blob/master/dynamic_rnn.ipynb>`__\n",
    "    - `tf.nn.dynamic_rnn <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard8/tf.nn.dynamic_rnn.md>`__\n",
    "    - `tflearn rnn <https://github.com/tflearn/tflearn/blob/master/tflearn/layers/recurrent.py>`__\n",
    "    - ``tutorial_dynamic_rnn.py``\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            layer,\n",
    "            cell_fn,  #tf.nn.rnn_cell.LSTMCell,\n",
    "            attention_mechanism_fn,\n",
    "            memory,\n",
    "            cell_init_args=None,\n",
    "            n_hidden=256,\n",
    "            initializer=tf.random_uniform_initializer(-0.1, 0.1),\n",
    "            sequence_length=None,\n",
    "            initial_state=None,\n",
    "            dropout=None,\n",
    "            n_layer=1,\n",
    "            return_last=None,\n",
    "            return_seq_2d=False,\n",
    "            dynamic_rnn_init_args=None,\n",
    "            name='dyrnn',\n",
    "    ):\n",
    "#         self.initial_state_from_encoder = initial_state\n",
    "        \n",
    "        if dynamic_rnn_init_args is None:\n",
    "            dynamic_rnn_init_args = {}\n",
    "        if cell_init_args is None:\n",
    "            cell_init_args = {'state_is_tuple': True}\n",
    "        if return_last is None:\n",
    "            return_last = True\n",
    "\n",
    "        Layer.__init__(self, name=name)\n",
    "        if cell_fn is None:\n",
    "            raise Exception(\"Please put in cell_fn\")\n",
    "        if 'GRU' in cell_fn.__name__:\n",
    "            try:\n",
    "                cell_init_args.pop('state_is_tuple')\n",
    "            except Exception:\n",
    "                logging.warning(\"pop state_is_tuple fails.\")\n",
    "        self.inputs = layer.outputs\n",
    "        self.memory = memory\n",
    "        print(\"  [TL] DynamicRNNLayerWithAttention %s: n_hidden:%d, in_dim:%d in_shape:%s cell_fn:%s dropout:%s n_layer:%d\" %\n",
    "                     (self.name, n_hidden, self.inputs.get_shape().ndims, self.inputs.get_shape(), cell_fn.__name__, dropout, n_layer))\n",
    "\n",
    "        logging.info(\"DynamicRNNLayerWithAttention %s: n_hidden:%d, in_dim:%d in_shape:%s cell_fn:%s dropout:%s n_layer:%d\" %\n",
    "                     (self.name, n_hidden, self.inputs.get_shape().ndims, self.inputs.get_shape(), cell_fn.__name__, dropout, n_layer))\n",
    "\n",
    "        # Input dimension should be rank 3 [batch_size, n_steps(max), n_features]\n",
    "        try:\n",
    "            self.inputs.get_shape().with_rank(3)\n",
    "        except Exception:\n",
    "            raise Exception(\"RNN : Input dimension should be rank 3 : [batch_size, n_steps(max), n_features]\")\n",
    "\n",
    "        # Get the batch_size\n",
    "        fixed_batch_size = self.inputs.get_shape().with_rank_at_least(1)[0]\n",
    "        if fixed_batch_size.value:\n",
    "            batch_size = fixed_batch_size.value\n",
    "            logging.info(\"       batch_size (concurrent processes): %d\" % batch_size)\n",
    "        else:\n",
    "            from tensorflow.python.ops import array_ops\n",
    "            batch_size = array_ops.shape(self.inputs)[0]\n",
    "            logging.info(\"       non specified batch_size, uses a tensor instead.\")\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Creats the cell function\n",
    "        # cell_instance_fn=lambda: cell_fn(num_units=n_hidden, **cell_init_args) # HanSheng\n",
    "        rnn_creator = lambda: cell_fn(num_units=n_hidden, **cell_init_args)\n",
    "        \n",
    "        # ============================ PLJ added attention mechanism ====================================\n",
    "        attention_mechanism = attention_mechanism_fn(num_units = n_hidden,\n",
    "                                memory = self.memory,\n",
    "                                memory_sequence_length = None # Might be made more accurate later \n",
    "                                )\n",
    "        attn_cell_creator = lambda: tf.contrib.seq2seq.AttentionWrapper(rnn_creator(), attention_mechanism)\n",
    "        # ===============================================================================================            \n",
    "        # Apply dropout\n",
    "        if dropout:\n",
    "            if isinstance(dropout, (tuple, list)):\n",
    "                in_keep_prob = dropout[0]\n",
    "                out_keep_prob = dropout[1]\n",
    "            elif isinstance(dropout, float):\n",
    "                in_keep_prob, out_keep_prob = dropout, dropout\n",
    "            else:\n",
    "                raise Exception(\"Invalid dropout type (must be a 2-D tuple of \" \"float)\")\n",
    "            try:  # TF1.0\n",
    "                DropoutWrapper_fn = tf.contrib.rnn.DropoutWrapper\n",
    "            except Exception:\n",
    "                DropoutWrapper_fn = tf.nn.rnn_cell.DropoutWrapper\n",
    "\n",
    "            # cell_instance_fn1=cell_instance_fn        # HanSheng\n",
    "            # cell_instance_fn=DropoutWrapper_fn(\n",
    "            #                     cell_instance_fn1(),\n",
    "            #                     input_keep_prob=in_keep_prob,\n",
    "            #                     output_keep_prob=out_keep_prob)\n",
    "            cell_creator = lambda is_last=True: \\\n",
    "                    DropoutWrapper_fn(attn_cell_creator(),\n",
    "                                      input_keep_prob=in_keep_prob,\n",
    "                                      output_keep_prob=out_keep_prob if is_last else 1.0)\n",
    "        else:\n",
    "            cell_creator = attn_cell_creator\n",
    "        self.cell = cell_creator()\n",
    "        # Apply multiple layers\n",
    "        if n_layer > 1:\n",
    "            try:\n",
    "                MultiRNNCell_fn = tf.contrib.rnn.MultiRNNCell\n",
    "            except Exception:\n",
    "                MultiRNNCell_fn = tf.nn.rnn_cell.MultiRNNCell\n",
    "\n",
    "            # cell_instance_fn2=cell_instance_fn # HanSheng\n",
    "            try:\n",
    "                # cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)], state_is_tuple=True) # HanSheng\n",
    "                self.cell = MultiRNNCell_fn([cell_creator(is_last=i == n_layer - 1) for i in range(n_layer)], state_is_tuple=True)\n",
    "            except Exception:  # when GRU\n",
    "                # cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)]) # HanSheng\n",
    "                self.cell = MultiRNNCell_fn([cell_creator(is_last=i == n_layer - 1) for i in range(n_layer)])\n",
    "\n",
    "        # self.cell=cell_instance_fn() # HanSheng\n",
    "\n",
    "        # Initialize initial_state\n",
    "        if initial_state is None:\n",
    "            self.initial_state = self.cell.zero_state(batch_size, dtype=D_TYPE)  # dtype=tf.float32)\n",
    "        else:\n",
    "            try:\n",
    "                self.initial_state = self.cell.zero_state(batch_size, dtype=D_TYPE).clone(cell_state=initial_state) \n",
    "            except AttributeError:\n",
    "                self.initial_state = initial_state\n",
    "\n",
    "        # Computes sequence_length\n",
    "        if sequence_length is None:\n",
    "            try:  # TF1.0\n",
    "                sequence_length = retrieve_seq_length_op(self.inputs if isinstance(self.inputs, tf.Tensor) else tf.stack(self.inputs))\n",
    "            except Exception:  # TF0.12\n",
    "                sequence_length = retrieve_seq_length_op(self.inputs if isinstance(self.inputs, tf.Tensor) else tf.pack(self.inputs))\n",
    "        \n",
    "        # Main - Computes outputs and last_states\n",
    "#         with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        with tf.variable_scope(name, initializer=initializer) as vs:\n",
    "            outputs, last_states = tf.nn.dynamic_rnn(\n",
    "                cell=self.cell,\n",
    "                # inputs=X\n",
    "                inputs=self.inputs,\n",
    "                dtype=tf.float32,\n",
    "                sequence_length=sequence_length,\n",
    "                initial_state=self.initial_state,\n",
    "                **dynamic_rnn_init_args)\n",
    "            rnn_variables = tf.get_collection(TF_GRAPHKEYS_VARIABLES, scope=vs.name)\n",
    "\n",
    "            # logging.info(\"     n_params : %d\" % (len(rnn_variables)))\n",
    "            # Manage the outputs\n",
    "            if return_last:\n",
    "                # [batch_size, n_hidden]\n",
    "                # outputs = tf.transpose(tf.pack(outputs), [1, 0, 2]) # TF1.0 tf.pack --> tf.stack\n",
    "                self.outputs = advanced_indexing_op(outputs, sequence_length)\n",
    "            else:\n",
    "                # [batch_size, n_step(max), n_hidden]\n",
    "                # self.outputs = result[0][\"outputs\"]\n",
    "                # self.outputs = outputs    # it is 3d, but it is a list\n",
    "                if return_seq_2d:\n",
    "                    # PTB tutorial:\n",
    "                    # 2D Tensor [n_example, n_hidden]\n",
    "                    try:  # TF1.0\n",
    "                        self.outputs = tf.reshape(tf.concat(outputs, 1), [-1, n_hidden])\n",
    "                    except Exception:  # TF0.12\n",
    "                        self.outputs = tf.reshape(tf.concat(1, outputs), [-1, n_hidden])\n",
    "                else:\n",
    "                    # <akara>:\n",
    "                    # 3D Tensor [batch_size, n_steps(max), n_hidden]\n",
    "                    max_length = tf.shape(outputs)[1]\n",
    "                    batch_size = tf.shape(outputs)[0]\n",
    "\n",
    "                    try:  # TF1.0\n",
    "                        self.outputs = tf.reshape(tf.concat(outputs, 1), [batch_size, max_length, n_hidden])\n",
    "                    except Exception:  # TF0.12\n",
    "                        self.outputs = tf.reshape(tf.concat(1, outputs), [batch_size, max_length, n_hidden])\n",
    "                    # self.outputs = tf.reshape(tf.concat(1, outputs), [-1, max_length, n_hidden])\n",
    "#             tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        # Final state\n",
    "        self.final_state = last_states\n",
    "\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.all_layers = list(layer.all_layers)\n",
    "        self.all_params = list(layer.all_params)\n",
    "        self.all_drop = dict(layer.all_drop)\n",
    "\n",
    "        self.all_layers.extend([self.outputs])\n",
    "        self.all_params.extend(rnn_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # model for training\n",
    "# encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\") # encoding input  ['It', 'was', 'choking', 'with', 'smoke', '.', '_', '_']\n",
    "# decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\") # decoding input  ['start_id', 'N', 'c', 'khi', '.', '_']\n",
    "# target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\") # decoding output ['N', 'c', 'khi', '.', 'end_id', '_']\n",
    "# target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") # tl.prepro.sequences_get_mask()\n",
    "# net_out, _, net_encode = model(encode_seqs, decode_seqs, is_train=True, reuse=False)\n",
    "\n",
    "# # model for inferencing\n",
    "# encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "# decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "# net, net_rnn, _ = model(encode_seqs2, decode_seqs2, is_train=False, reuse=True)\n",
    "# y = tf.nn.softmax(net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [TL] EmbeddingInputlayer model/embedding/encode_seq_embedding: (50004, 200)\n",
      "  [TL] EmbeddingInputlayer model/embedding/decode_seq_embedding: (131832, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [TL] DynamicRNNLayer model/seq2seq_encode: n_hidden:200, in_dim:3 in_shape:(16, ?, 200) cell_fn:BasicLSTMCell dropout:0.5 n_layer:1\n",
      "       batch_size (concurrent processes): 16\n",
      "  [TL] DynamicRNNLayerWithAttention model/seq2seq_decode: n_hidden:200, in_dim:3 in_shape:(16, ?, 200) cell_fn:BasicLSTMCell dropout:0.5 n_layer:1\n",
      "  [TL] DenseLayer  model/output: 131832 identity\n",
      "  [TL] EmbeddingInputlayer model/embedding/encode_seq_embedding: (50004, 200)\n",
      "  [TL] EmbeddingInputlayer model/embedding/decode_seq_embedding: (131832, 200)\n",
      "  [TL] DynamicRNNLayer model/seq2seq_encode: n_hidden:200, in_dim:3 in_shape:(1, ?, 200) cell_fn:BasicLSTMCell dropout:None n_layer:1\n",
      "       batch_size (concurrent processes): 1\n",
      "  [TL] DynamicRNNLayerWithAttention model/seq2seq_decode: n_hidden:200, in_dim:3 in_shape:(1, ?, 200) cell_fn:BasicLSTMCell dropout:None n_layer:1\n",
      "  [TL] DenseLayer  model/output: 131832 identity\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default() as graph:\n",
    "    tl.layers.clear_layers_name()\n",
    "\n",
    "    # model for training\n",
    "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\") # encoding input  ['It', 'was', 'choking', 'with', 'smoke', '.', '_', '_']\n",
    "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\") # decoding input  ['start_id', 'N', 'c', 'khi', '.', '_']\n",
    "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\") # decoding output ['N', 'c', 'khi', '.', 'end_id', '_']\n",
    "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") # tl.prepro.sequences_get_mask()\n",
    "    net_out, _, net_encode, _, _ = modelWithAttention(encode_seqs, decode_seqs, is_train=True, reuse=False)\n",
    "\n",
    "    # model for inferencing\n",
    "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "    net, net_rnn, _, network_decode, cell = modelWithAttention(encode_seqs2, decode_seqs2, is_train=False, reuse=True)\n",
    "    y = tf.nn.softmax(net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param   0: model/embedding/decode_seq_embedding/embeddings:0 (131832, 200)      float32_ref\n",
      "  param   1: model/seq2seq_decode/rnn/attention_wrapper/basic_lstm_cell/kernel:0 (600, 800)         float32_ref\n",
      "  param   2: model/seq2seq_decode/rnn/attention_wrapper/basic_lstm_cell/bias:0 (800,)             float32_ref\n",
      "  param   3: model/seq2seq_decode/rnn/attention_wrapper/bahdanau_attention/query_layer/kernel:0 (200, 200)         float32_ref\n",
      "  param   4: model/seq2seq_decode/rnn/attention_wrapper/bahdanau_attention/attention_v:0 (200,)             float32_ref\n",
      "  param   5: model/output/W:0     (200, 131832)      float32_ref\n",
      "  param   6: model/output/b:0     (131832,)          float32_ref\n",
      "  num of params: 53385632\n"
     ]
    }
   ],
   "source": [
    "with g.as_default() as graph:\n",
    "    loss = tl.cost.cross_entropy_seq_with_mask(logits=net_out.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n",
    "    net_out.print_params(False)\n",
    "    lr = 0.0001\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Load T2BWithAttention.npz failed!\n"
     ]
    }
   ],
   "source": [
    "with g.as_default() as graph:\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    tl.files.assign_params(sess, [word_embedding], net_encode)\n",
    "    tl.files.load_and_assign_npz(sess=sess, name='T2BWithAttention.npz', network=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T_vocab_size_total)\n",
    "print(word_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50] step:[0/657] loss:4.178650 took:5.39901s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[10/657] loss:4.246622 took:6.13321s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[20/657] loss:4.108953 took:4.94277s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[30/657] loss:4.110910 took:6.49201s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[40/657] loss:4.219381 took:5.13368s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ( ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[50/657] loss:4.212671 took:5.68776s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[60/657] loss:4.132235 took:6.61504s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[70/657] loss:4.346044 took:5.44294s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[80/657] loss:4.194221 took:5.17438s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[90/657] loss:3.854002 took:5.00523s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[100/657] loss:4.021791 took:6.50789s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[110/657] loss:3.914396 took:6.42969s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ( ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[120/657] loss:3.893622 took:6.77400s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[130/657] loss:4.157356 took:5.80566s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[140/657] loss:3.963206 took:5.26021s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ( ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[150/657] loss:3.997135 took:6.34582s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[160/657] loss:4.008140 took:6.88293s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[170/657] loss:3.978844 took:6.21644s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[180/657] loss:3.929375 took:5.01399s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[190/657] loss:3.947821 took:5.10813s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[200/657] loss:3.931256 took:5.48043s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[210/657] loss:3.650948 took:5.27995s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[220/657] loss:3.652513 took:6.52458s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[230/657] loss:3.805535 took:6.19732s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[240/657] loss:3.880276 took:6.30661s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[250/657] loss:3.803169 took:4.86602s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[260/657] loss:3.722643 took:6.63131s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[270/657] loss:3.893676 took:6.21355s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[280/657] loss:3.783005 took:6.71326s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[290/657] loss:3.697696 took:4.82010s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[300/657] loss:3.679973 took:6.29869s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[310/657] loss:3.678592 took:5.34017s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[320/657] loss:3.671165 took:5.13591s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[330/657] loss:3.618848 took:5.76837s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[340/657] loss:3.759000 took:6.58100s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[350/657] loss:3.727454 took:4.33958s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[360/657] loss:3.501790 took:6.28510s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[370/657] loss:3.571419 took:6.59684s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[380/657] loss:3.671924 took:5.54617s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[390/657] loss:3.660132 took:6.47364s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[400/657] loss:3.390727 took:5.12611s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/50] step:[410/657] loss:3.527538 took:6.84841s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[420/657] loss:3.634032 took:6.34836s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[430/657] loss:3.513031 took:5.81202s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[440/657] loss:3.466117 took:5.28283s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[450/657] loss:3.588979 took:6.39178s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[460/657] loss:3.336626 took:7.50870s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[470/657] loss:3.557574 took:6.28784s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[480/657] loss:3.548233 took:5.33699s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[490/657] loss:3.378099 took:5.74739s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[500/657] loss:3.382312 took:7.16695s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[510/657] loss:3.688719 took:4.95082s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[520/657] loss:3.460846 took:6.71461s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[530/657] loss:3.315448 took:4.85891s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[540/657] loss:3.518126 took:6.50130s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[550/657] loss:3.449219 took:5.51028s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[560/657] loss:3.480135 took:5.04772s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[570/657] loss:3.414946 took:5.08220s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[580/657] loss:3.415943 took:4.57633s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[590/657] loss:3.468820 took:6.49362s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[600/657] loss:3.448036 took:5.66177s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[610/657] loss:3.346661 took:5.82384s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[620/657] loss:3.489734 took:5.41955s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[630/657] loss:3.321966 took:8.05537s\n",
      "Input > F2 increases CSF3\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[640/657] loss:3.326446 took:3.06716s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[0/50] step:[650/657] loss:3.186152 took:2.82852s\n",
      "Epoch[0/50] averaged loss:3.710358 took:4108.25920s\n",
      "[*] T2BWithAttention.npz saved\n",
      "Epoch[1/50] step:[0/657] loss:3.375409 took:3.30679s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[1/50] step:[10/657] loss:3.231412 took:3.04309s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[1/50] step:[20/657] loss:3.505686 took:3.06114s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[1/50] step:[30/657] loss:3.349356 took:3.87931s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\n",
      "Epoch[1/50] step:[40/657] loss:3.433669 took:3.36294s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[50/657] loss:3.226269 took:2.82050s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[60/657] loss:3.481535 took:3.16542s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[70/657] loss:3.250093 took:2.84657s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[80/657] loss:3.156491 took:2.63798s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[90/657] loss:3.246717 took:2.64804s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[100/657] loss:3.034296 took:3.17845s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[110/657] loss:3.122292 took:2.49664s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[120/657] loss:3.010183 took:3.09824s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[130/657] loss:3.158051 took:2.60593s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[140/657] loss:3.248513 took:3.18547s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[150/657] loss:2.906554 took:3.29075s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[160/657] loss:3.043278 took:3.06214s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > p ) p ) p ) p ) p ) p ) p ) p ) p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[170/657] loss:3.175909 took:2.43648s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[180/657] loss:3.020996 took:3.30779s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[190/657] loss:3.055022 took:3.55746s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[200/657] loss:3.270465 took:2.56682s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[210/657] loss:3.042992 took:2.63400s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[220/657] loss:3.075572 took:3.36495s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[230/657] loss:2.960274 took:2.52371s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[240/657] loss:3.005152 took:2.98594s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[250/657] loss:2.842393 took:3.33286s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[260/657] loss:2.998094 took:4.11695s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[270/657] loss:2.879208 took:3.05813s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[280/657] loss:2.946582 took:3.02705s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[290/657] loss:2.895137 took:3.45519s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[300/657] loss:2.858680 took:3.12631s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[310/657] loss:2.861188 took:3.38600s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[320/657] loss:2.905003 took:3.28473s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[330/657] loss:2.709563 took:3.17243s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[340/657] loss:2.730562 took:2.61896s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[350/657] loss:2.638819 took:3.33788s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[360/657] loss:2.835009 took:3.40004s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[370/657] loss:2.757644 took:3.26669s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Epoch[1/50] step:[380/657] loss:2.718349 took:2.53273s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[390/657] loss:2.642221 took:3.04510s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[400/657] loss:2.650348 took:2.72224s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[410/657] loss:2.646030 took:3.59656s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[420/657] loss:2.554188 took:2.51369s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[430/657] loss:2.530534 took:3.22257s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[440/657] loss:2.689586 took:2.98594s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[450/657] loss:2.552083 took:4.13199s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[460/657] loss:2.647497 took:2.69916s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[470/657] loss:2.710234 took:2.77839s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[480/657] loss:2.591609 took:3.17544s\n",
      "Input > F2 increases CSF3\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > activation of IL6R inhibits mitosis\n",
      " > p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p p\n",
      "Input > Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\n",
      " > p p p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p ) p\n",
      "Epoch[1/50] step:[490/657] loss:2.403671 took:3.54743s\n"
     ]
    }
   ],
   "source": [
    "with g.as_default() as graph:\n",
    "    start_id = B_vocab_size_total-2\n",
    "    end_id = B_vocab_size_total-1\n",
    "    n_epoch = 50\n",
    "    n_step = int(len(trainT)/batch_size)\n",
    "    for epoch in range(n_epoch):\n",
    "        epoch_time = time.time()\n",
    "        ## shuffle training data\n",
    "        from sklearn.utils import shuffle\n",
    "        trainT, trainB = shuffle(trainT, trainB, random_state=0)\n",
    "        ## train an epoch\n",
    "        total_err, n_iter = 0, 0\n",
    "        for X, Y in tl.iterate.minibatches(inputs=trainT, targets=trainB, batch_size=batch_size, shuffle=False):\n",
    "            step_time = time.time()\n",
    "\n",
    "            X = tl.prepro.pad_sequences(X)\n",
    "            _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
    "            _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "\n",
    "            _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
    "            _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "            _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "\n",
    "            ## you can view the data here\n",
    "    #         for i in range(len(X)):\n",
    "    #             print(i, [E_idx2w[id] for id in X[i]])\n",
    "    #             print(i, [V_idx2w[id] for id in _target_seqs[i]])\n",
    "    #             print(i, [V_idx2w[id] for id in _decode_seqs[i]])\n",
    "    #             print(i, _target_mask[i])\n",
    "    #             print(len(_target_seqs[i]), len(_decode_seqs[i]), len(_target_mask[i]))\n",
    "            # exit()\n",
    "\n",
    "            _, err = sess.run([train_op, loss],\n",
    "                            {encode_seqs: X,\n",
    "                            decode_seqs: _decode_seqs,\n",
    "                            target_seqs: _target_seqs,\n",
    "                            target_mask: _target_mask})\n",
    "\n",
    "            if n_iter % 10 == 0:\n",
    "                print(\"Epoch[%d/%d] step:[%d/%d] loss:%f took:%.5fs\" % (epoch, n_epoch, n_iter, n_step, err, time.time() - step_time))\n",
    "\n",
    "            total_err += err; n_iter += 1\n",
    "\n",
    "            ###============= inference\n",
    "            if n_iter % 10 == 0:\n",
    "                seeds = [\"F2 increases CSF3\",\n",
    "                        \"activation of IL6R inhibits mitosis\",\n",
    "                        \"Thus, extramitochondrially targeted AIF is a dominant cell death inducer.\"] # p(MGI:Aifm1) increases bp(GOBP:\"cell death\")\n",
    "                for seed in seeds:\n",
    "                    print(\"Input >\", seed)\n",
    "                    output = nlp.annotate(seed, properties={'annotators': 'tokenize', 'outputFormat': 'json'})\n",
    "                    seed_tokens = [i['originalText'] for i in output['tokens']]\n",
    "                    seed_id = [T_w2idx[w] if w in T_w2idx else T_w2idx['unk'] for w in seed_tokens]\n",
    "\n",
    "    #                 # 1. encode, get state\n",
    "    #                 state = sess.run(net_rnn.final_state_encode,\n",
    "    #                                 {encode_seqs2: [seed_id]})\n",
    "    #                 # 2. decode, feed start_id, get first word\n",
    "    #                 #   ref https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py\n",
    "    #                 o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "    #                                 {net_rnn.initial_state_decode: state,\n",
    "    #                                 decode_seqs2: [[start_id]]})\n",
    "    #                 w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "    #                 w = B_idx2w[w_id]\n",
    "    #                 # 3. decode, feed state iteratively\n",
    "    #                 sentence = [w]\n",
    "    #                 for _ in range(30): # max sentence length\n",
    "    #                     o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "    #                                     {net_rnn.initial_state_decode: state,\n",
    "    #                                     decode_seqs2: [[w_id]]})\n",
    "    #                     w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "    #                     w = B_idx2w[w_id]\n",
    "    #                     if w_id == end_id:\n",
    "    #                         break\n",
    "    #                     sentence = sentence + [w]\n",
    "    #                 print(\" >\", ' '.join(sentence))\n",
    "\n",
    "                    # 1. encode, get state\n",
    "                    state, memory = sess.run([net_rnn.final_state, net_rnn.outputs],\n",
    "                                    {encode_seqs2: [seed_id]})\n",
    "                    # 2. decode, feed start_id, get first word\n",
    "                    #   ref https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py\n",
    "                    feed_dict = {network_decode.initial_state.cell_state:state,\n",
    "                                 network_decode.memory:memory,\n",
    "#                                     encode_seqs2: [seed_id],\n",
    "                                    decode_seqs2: [[start_id]]}\n",
    "#                     print(feed_dict)\n",
    "                    o, state = sess.run([y, network_decode.final_state],\n",
    "                                    feed_dict)\n",
    "                    w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "                    w = B_idx2w[w_id]\n",
    "                    # 3. decode, feed state iteratively\n",
    "                    sentence = [w]\n",
    "                    for _ in range(30): # max sentence length\n",
    "                        o, state = sess.run([y, network_decode.final_state],\n",
    "                                        {network_decode.initial_state:state,\n",
    "                                         network_decode.memory:memory,\n",
    "#                                          encode_seqs2: [seed_id],\n",
    "                                        decode_seqs2: [[w_id]]})\n",
    "                        w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "                        w = B_idx2w[w_id] ###\n",
    "                        if w_id == end_id:\n",
    "                            break\n",
    "                        sentence = sentence + [w]\n",
    "                    print(\" >\", ' '.join(sentence))\n",
    "\n",
    "        print(\"Epoch[%d/%d] averaged loss:%f took:%.5fs\" % (epoch, n_epoch, total_err/n_iter, time.time()-epoch_time))\n",
    "\n",
    "        tl.files.save_npz(net.all_params, name='T2BWithAttention.npz', sess=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "sentences = loadSentences('dataset/Task1NeuV3_corrected.sentence')\n",
    "sampleTSentences = [TextSentenceID[line['Sentence-ID'][4:]]['text'] for line in sentences]\n",
    "sampleTTokenized = [TextSentenceID[line['Sentence-ID'][4:]]['tokens'] for line in sentences]\n",
    "sampleT = [words2index(sublist, T_w2idx) for sublist in sampleTTokenized]\n",
    "f = open('results/Task1NeuV3_corrected' + '_' + strftime(\"%Y%m%d%H%M%S\", gmtime()) +'.txt', 'w')\n",
    "for i in range(len(sampleT)):\n",
    "    sentence_id = sentences[i]['Sentence-ID'][4:]\n",
    "    seed_id = sampleT[i]\n",
    "    # 1. encode, get state\n",
    "    state = sess.run(net_rnn.final_state_encode,\n",
    "                    {encode_seqs2: [seed_id]})\n",
    "    # 2. decode, feed start_id, get first word\n",
    "    #   ref https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py\n",
    "    o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                    {net_rnn.initial_state_decode: state,\n",
    "                    decode_seqs2: [[start_id]]})\n",
    "    w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "    w = B_idx2w[w_id]\n",
    "    # 3. decode, feed state iteratively\n",
    "    sentence = [w]\n",
    "    for _ in range(30): # max sentence length\n",
    "        o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                        {net_rnn.initial_state_decode: state,\n",
    "                        decode_seqs2: [[w_id]]})\n",
    "        w_id = tl.nlp.sample_top(o[0], top_k=1)\n",
    "        w = B_idx2w[w_id]\n",
    "        if w_id == end_id:\n",
    "            break\n",
    "        sentence = sentence + [w]\n",
    "    f.write(sentence_id + '\\t' + ''.join(sentence) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param   0: embedding_layer/embeddings:0 (5000, 200)        float32_ref (mean: 8.860853995429352e-05, median: -7.748603820800781e-06, std: 0.05772264301776886)   \n",
      "  num of params: 1000000\n",
      "  layer   0: embedding_layer/embedding_lookup:0 <unknown>          float32\n",
      "vector: (2, 200)\n",
      "[[-0.0814091  -0.02825403 -0.05328007 -0.02780311 -0.0653923  -0.02430246\n",
      "   0.01921391  0.09056108 -0.09929579 -0.04090867 -0.01154137  0.09985436\n",
      "  -0.01916699 -0.00505853  0.04639273 -0.0912411   0.05427978 -0.09722042\n",
      "  -0.00647257  0.08200861  0.02909157 -0.04913936 -0.02959277 -0.0851137\n",
      "   0.00671704  0.09491635 -0.05910125  0.091788   -0.06434856  0.06943984\n",
      "  -0.04222007  0.07136836 -0.01448791  0.08609817  0.00808146  0.03219343\n",
      "   0.04411275  0.09080558 -0.03130624 -0.00718544  0.08492801  0.07755976\n",
      "   0.00010915 -0.04611282 -0.00340497  0.07246631  0.03042834 -0.06478818\n",
      "  -0.01676147 -0.09139509 -0.01971438  0.09120715 -0.07756324 -0.06961818\n",
      "   0.03664833  0.02337506  0.09040568  0.00635266 -0.0232677   0.05131922\n",
      "  -0.00828378 -0.01890366  0.06180627 -0.06814513 -0.08772276  0.04930117\n",
      "  -0.00804181 -0.04816544 -0.02040946 -0.03723578  0.07128019  0.03358342\n",
      "   0.00175945 -0.02590559  0.06626294 -0.02632751 -0.01080777  0.06166667\n",
      "   0.01842217  0.09664319  0.06897724 -0.03472135  0.03253455  0.08549\n",
      "  -0.0626477  -0.071293    0.05145519 -0.02030382 -0.06248679  0.06851809\n",
      "  -0.08399463  0.04801769 -0.02574372 -0.02769997 -0.07764652  0.01641035\n",
      "  -0.03789518  0.07727473 -0.00599911  0.03927872  0.09613699  0.07379954\n",
      "  -0.02546068 -0.02422182  0.03840404 -0.05792975  0.08899603 -0.0242872\n",
      "  -0.01208117  0.04193506  0.0466134  -0.00183616 -0.02659454 -0.05663202\n",
      "  -0.07311726 -0.04884579 -0.05285804  0.01320484  0.02943525  0.04767544\n",
      "  -0.04150379  0.04774421 -0.05702195  0.06494596  0.00429349  0.0283756\n",
      "   0.09109474 -0.0475939  -0.07945001  0.06320525  0.06294789 -0.01478086\n",
      "   0.01389126 -0.09139919 -0.07270155  0.08053074 -0.07187185  0.02230828\n",
      "  -0.06168561  0.05019607  0.07826624 -0.02464239 -0.0066149  -0.03240955\n",
      "  -0.00385229 -0.04082232  0.08280382  0.08113091  0.05908503  0.04457793\n",
      "   0.03791159 -0.05727065  0.07495577 -0.07586212  0.01279597 -0.01022656\n",
      "  -0.09589694  0.07789364 -0.09572859 -0.01214912  0.07901294  0.08805538\n",
      "  -0.04041016  0.07057705  0.08430853  0.08616345  0.03034756  0.00775909\n",
      "  -0.01162942 -0.04242444  0.0576852   0.06635147 -0.03459122  0.09529198\n",
      "   0.08264447 -0.00417671  0.0068717  -0.02541959 -0.00895784  0.05633502\n",
      "  -0.02023423 -0.03201754  0.05500247 -0.07538845 -0.05355556  0.05799859\n",
      "   0.04012611 -0.00756764  0.01735234 -0.05125139  0.05509795 -0.05667336\n",
      "   0.02523936 -0.0846457   0.05294753 -0.08508065  0.06113666  0.06722381\n",
      "   0.09179395  0.02792025]\n",
      " [-0.07300625 -0.07178338  0.03270917  0.02948902 -0.0277539   0.06138358\n",
      "   0.01017196  0.05118606  0.07188684  0.00764177  0.03073985  0.01912494\n",
      "  -0.0554651   0.09886403  0.05280008 -0.07176642 -0.01712229  0.04176099\n",
      "   0.08187693 -0.04940658  0.04932959 -0.08736575  0.00255685 -0.05939186\n",
      "   0.07234604  0.07320827  0.09319598  0.00945397 -0.06233375  0.09591132\n",
      "  -0.08581748  0.07480397  0.07413114 -0.07826877  0.06565262  0.07895332\n",
      "  -0.01523657  0.00368941  0.09828029 -0.07414506 -0.03695448  0.08246288\n",
      "  -0.04058111 -0.07034735  0.09547866  0.08615381  0.05937629  0.08408075\n",
      "  -0.0946728  -0.071436   -0.03142031 -0.05875225  0.03170896 -0.03995001\n",
      "  -0.05601905 -0.01631327  0.05138335  0.04079201 -0.02838822  0.01236143\n",
      "   0.02981863 -0.07603975 -0.09796383 -0.03586268  0.04894937 -0.08194108\n",
      "  -0.03211312  0.08084717  0.06780542  0.0815691   0.08265116  0.0399312\n",
      "   0.09664    -0.04039614  0.03961148  0.06069844 -0.03849268 -0.03772125\n",
      "   0.02506114 -0.06698456 -0.09672111 -0.04906936 -0.02565558 -0.09466188\n",
      "   0.02353255  0.03603256 -0.0246475  -0.01452675 -0.00609956  0.01105201\n",
      "   0.09204819  0.06644251  0.06744719  0.08946664 -0.06974413 -0.09007275\n",
      "  -0.09396081  0.08545353  0.05483625  0.0232409   0.02502979  0.06613901\n",
      "  -0.05347154 -0.0361017  -0.06437609 -0.09312048  0.09458341 -0.07405777\n",
      "  -0.04676099  0.08480825 -0.08298071  0.020889   -0.07577868 -0.09467714\n",
      "  -0.01385655 -0.0227139   0.0305594   0.08777613  0.02581833  0.08205888\n",
      "   0.03562503 -0.06550424  0.07668728  0.05511682  0.05298973  0.05726523\n",
      "   0.04314273  0.04790816  0.02070372 -0.03391834 -0.09062868  0.09224934\n",
      "  -0.080515    0.09436899 -0.06191218 -0.07492499 -0.089097   -0.06039946\n",
      "   0.03624525  0.03962327 -0.00243914  0.07183299  0.06922155 -0.03958762\n",
      "  -0.01138282 -0.03288285  0.09082942  0.07501061  0.08312655 -0.07457254\n",
      "  -0.05529845  0.0806495  -0.07204566 -0.06080637  0.03589792  0.03760848\n",
      "   0.07028156 -0.04214993 -0.025786   -0.02254999  0.07231285  0.06653474\n",
      "   0.09377065  0.0376678  -0.06156909  0.02581067  0.06655353  0.08348911\n",
      "   0.0017391  -0.03146541 -0.07708132  0.09916549  0.01593781 -0.05660055\n",
      "  -0.04595266  0.05953134 -0.05407255 -0.04759119 -0.08280241  0.00292838\n",
      "  -0.0047915   0.04714618  0.02449934 -0.0954896   0.03650897 -0.05131836\n",
      "  -0.04769087 -0.04874864 -0.07176153  0.07729378  0.08030932  0.04159778\n",
      "   0.06162589 -0.05630584 -0.07728694 -0.02744737 -0.04501798 -0.02628002\n",
      "  -0.05703549 -0.04510691]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# sess.run(tf.initialize_all_variables())\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "\n",
    "# tl.files.assign_params(sess, [load_params[0]], emb_net)\n",
    "# print(sess.run(emb_net, {x:[1000, 1200]}))\n",
    "\n",
    "emb_net.print_params()\n",
    "emb_net.print_layers()\n",
    "\n",
    "vector = sess.run(emb_net.outputs, feed_dict={x : [1000,122]})\n",
    "print('vector:', vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Assign:0' shape=(5000, 200) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pretrained = np.array([np.array([i for _ in range(200)]) for i in range(5000)])\n",
    "tl.files.assign_params(sess, [embed_pretrained], emb_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector: (2, 200)\n",
      "[[1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.\n",
      "  1000. 1000. 1000. 1000. 1000. 1000. 1000. 1000.]\n",
      " [ 122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.  122.\n",
      "   122.  122.  122.  122.  122.  122.  122.  122.]]\n"
     ]
    }
   ],
   "source": [
    "vector = sess.run(emb_net.outputs, feed_dict={x : [1000,122]})\n",
    "print('vector:', vector.shape)\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
